{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Namespace Logo](../labs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('transfusion.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recency (months)</th>\n",
       "      <th>Frequency (times)</th>\n",
       "      <th>Monetary (c.c. blood)</th>\n",
       "      <th>Time (months)</th>\n",
       "      <th>whether he/she donated blood in March 2007</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>12500</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3250</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4000</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>5000</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>6000</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recency (months)  Frequency (times)  Monetary (c.c. blood)  Time (months)  \\\n",
       "0                 2                 50                  12500             98   \n",
       "1                 0                 13                   3250             28   \n",
       "2                 1                 16                   4000             35   \n",
       "3                 2                 20                   5000             45   \n",
       "4                 1                 24                   6000             77   \n",
       "\n",
       "   whether he/she donated blood in March 2007  \n",
       "0                                           1  \n",
       "1                                           1  \n",
       "2                                           1  \n",
       "3                                           1  \n",
       "4                                           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recency (months)</th>\n",
       "      <th>Frequency (times)</th>\n",
       "      <th>Monetary (c.c. blood)</th>\n",
       "      <th>Time (months)</th>\n",
       "      <th>whether he/she donated blood in March 2007</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>748.000000</td>\n",
       "      <td>748.000000</td>\n",
       "      <td>748.000000</td>\n",
       "      <td>748.000000</td>\n",
       "      <td>748.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.506684</td>\n",
       "      <td>5.514706</td>\n",
       "      <td>1378.676471</td>\n",
       "      <td>34.282086</td>\n",
       "      <td>0.237968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.095396</td>\n",
       "      <td>5.839307</td>\n",
       "      <td>1459.826781</td>\n",
       "      <td>24.376714</td>\n",
       "      <td>0.426124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1750.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>12500.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Recency (months)  Frequency (times)  Monetary (c.c. blood)  \\\n",
       "count        748.000000         748.000000             748.000000   \n",
       "mean           9.506684           5.514706            1378.676471   \n",
       "std            8.095396           5.839307            1459.826781   \n",
       "min            0.000000           1.000000             250.000000   \n",
       "25%            2.750000           2.000000             500.000000   \n",
       "50%            7.000000           4.000000            1000.000000   \n",
       "75%           14.000000           7.000000            1750.000000   \n",
       "max           74.000000          50.000000           12500.000000   \n",
       "\n",
       "       Time (months)  whether he/she donated blood in March 2007  \n",
       "count     748.000000                                  748.000000  \n",
       "mean       34.282086                                    0.237968  \n",
       "std        24.376714                                    0.426124  \n",
       "min         2.000000                                    0.000000  \n",
       "25%        16.000000                                    0.000000  \n",
       "50%        28.000000                                    0.000000  \n",
       "75%        50.000000                                    0.000000  \n",
       "max        98.000000                                    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['whether he/she donated blood in March 2007'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['whether he/she donated blood in March 2007']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sc.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    \n",
    "        Dense(20,activation='relu',input_dim=4),\n",
    "        Dense(15,activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(25,activation='relu'),\n",
    "        Dense(1,activation=keras.activations.sigmoid)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.6993 - accuracy: 0.4837 - val_loss: 0.6784 - val_accuracy: 0.7422\n",
      "Epoch 2/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6639 - accuracy: 0.7476 - val_loss: 0.6436 - val_accuracy: 0.7467\n",
      "Epoch 3/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6318 - accuracy: 0.7686 - val_loss: 0.6133 - val_accuracy: 0.7467\n",
      "Epoch 4/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6004 - accuracy: 0.7686 - val_loss: 0.5843 - val_accuracy: 0.7467\n",
      "Epoch 5/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5729 - accuracy: 0.7686 - val_loss: 0.5659 - val_accuracy: 0.7467\n",
      "Epoch 6/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5583 - accuracy: 0.7686 - val_loss: 0.5549 - val_accuracy: 0.7467\n",
      "Epoch 7/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.7686 - val_loss: 0.5495 - val_accuracy: 0.7467\n",
      "Epoch 8/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.7686 - val_loss: 0.5454 - val_accuracy: 0.7467\n",
      "Epoch 9/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5313 - accuracy: 0.7686 - val_loss: 0.5434 - val_accuracy: 0.7467\n",
      "Epoch 10/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5167 - accuracy: 0.7686 - val_loss: 0.5408 - val_accuracy: 0.7467\n",
      "Epoch 11/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7744 - val_loss: 0.5383 - val_accuracy: 0.7467\n",
      "Epoch 12/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5081 - accuracy: 0.7725 - val_loss: 0.5365 - val_accuracy: 0.7511\n",
      "Epoch 13/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5092 - accuracy: 0.7706 - val_loss: 0.5337 - val_accuracy: 0.7467\n",
      "Epoch 14/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7820 - val_loss: 0.5304 - val_accuracy: 0.7422\n",
      "Epoch 15/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7763 - val_loss: 0.5284 - val_accuracy: 0.7422\n",
      "Epoch 16/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4968 - accuracy: 0.7801 - val_loss: 0.5258 - val_accuracy: 0.7422\n",
      "Epoch 17/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4882 - accuracy: 0.7878 - val_loss: 0.5226 - val_accuracy: 0.7467\n",
      "Epoch 18/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4918 - accuracy: 0.7763 - val_loss: 0.5237 - val_accuracy: 0.7422\n",
      "Epoch 19/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7820 - val_loss: 0.5191 - val_accuracy: 0.7467\n",
      "Epoch 20/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7897 - val_loss: 0.5165 - val_accuracy: 0.7467\n",
      "Epoch 21/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4880 - accuracy: 0.7725 - val_loss: 0.5126 - val_accuracy: 0.7467\n",
      "Epoch 22/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7782 - val_loss: 0.5083 - val_accuracy: 0.7422\n",
      "Epoch 23/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4714 - accuracy: 0.7820 - val_loss: 0.5094 - val_accuracy: 0.7511\n",
      "Epoch 24/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.7801 - val_loss: 0.5047 - val_accuracy: 0.7467\n",
      "Epoch 25/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4809 - accuracy: 0.7782 - val_loss: 0.5031 - val_accuracy: 0.7467\n",
      "Epoch 26/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.7763 - val_loss: 0.4994 - val_accuracy: 0.7467\n",
      "Epoch 27/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7820 - val_loss: 0.4985 - val_accuracy: 0.7467\n",
      "Epoch 28/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.7859 - val_loss: 0.4990 - val_accuracy: 0.7511\n",
      "Epoch 29/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.7801 - val_loss: 0.4933 - val_accuracy: 0.7422\n",
      "Epoch 30/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4777 - accuracy: 0.7859 - val_loss: 0.4947 - val_accuracy: 0.7467\n",
      "Epoch 31/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7801 - val_loss: 0.4935 - val_accuracy: 0.7422\n",
      "Epoch 32/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4705 - accuracy: 0.7859 - val_loss: 0.4928 - val_accuracy: 0.7422\n",
      "Epoch 33/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7801 - val_loss: 0.4931 - val_accuracy: 0.7422\n",
      "Epoch 34/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7820 - val_loss: 0.4916 - val_accuracy: 0.7422\n",
      "Epoch 35/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7820 - val_loss: 0.4929 - val_accuracy: 0.7467\n",
      "Epoch 36/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7897 - val_loss: 0.4900 - val_accuracy: 0.7644\n",
      "Epoch 37/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7801 - val_loss: 0.4871 - val_accuracy: 0.7644\n",
      "Epoch 38/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7820 - val_loss: 0.4910 - val_accuracy: 0.7467\n",
      "Epoch 39/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7859 - val_loss: 0.4878 - val_accuracy: 0.7689\n",
      "Epoch 40/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7839 - val_loss: 0.4911 - val_accuracy: 0.7467\n",
      "Epoch 41/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7839 - val_loss: 0.4869 - val_accuracy: 0.7600\n",
      "Epoch 42/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7859 - val_loss: 0.4864 - val_accuracy: 0.7644\n",
      "Epoch 43/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7839 - val_loss: 0.4862 - val_accuracy: 0.7600\n",
      "Epoch 44/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7859 - val_loss: 0.4858 - val_accuracy: 0.7644\n",
      "Epoch 45/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7820 - val_loss: 0.4850 - val_accuracy: 0.7644\n",
      "Epoch 46/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7801 - val_loss: 0.4854 - val_accuracy: 0.7644\n",
      "Epoch 47/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7820 - val_loss: 0.4847 - val_accuracy: 0.7644\n",
      "Epoch 48/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7839 - val_loss: 0.4839 - val_accuracy: 0.7733\n",
      "Epoch 49/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7782 - val_loss: 0.4830 - val_accuracy: 0.7644\n",
      "Epoch 50/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.7839 - val_loss: 0.4837 - val_accuracy: 0.7733\n",
      "Epoch 51/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7744 - val_loss: 0.4842 - val_accuracy: 0.7644\n",
      "Epoch 52/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7801 - val_loss: 0.4817 - val_accuracy: 0.7733\n",
      "Epoch 53/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7820 - val_loss: 0.4815 - val_accuracy: 0.7733\n",
      "Epoch 54/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7839 - val_loss: 0.4825 - val_accuracy: 0.7733\n",
      "Epoch 55/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7954 - val_loss: 0.4848 - val_accuracy: 0.7644\n",
      "Epoch 56/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7763 - val_loss: 0.4814 - val_accuracy: 0.7733\n",
      "Epoch 57/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4736 - accuracy: 0.7820 - val_loss: 0.4815 - val_accuracy: 0.7644\n",
      "Epoch 58/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7782 - val_loss: 0.4803 - val_accuracy: 0.7644\n",
      "Epoch 59/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7763 - val_loss: 0.4785 - val_accuracy: 0.7778\n",
      "Epoch 60/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7859 - val_loss: 0.4779 - val_accuracy: 0.7778\n",
      "Epoch 61/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7859 - val_loss: 0.4804 - val_accuracy: 0.7644\n",
      "Epoch 62/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7878 - val_loss: 0.4771 - val_accuracy: 0.7822\n",
      "Epoch 63/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7782 - val_loss: 0.4771 - val_accuracy: 0.7778\n",
      "Epoch 64/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7801 - val_loss: 0.4788 - val_accuracy: 0.7778\n",
      "Epoch 65/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7839 - val_loss: 0.4784 - val_accuracy: 0.7822\n",
      "Epoch 66/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7859 - val_loss: 0.4795 - val_accuracy: 0.7778\n",
      "Epoch 67/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7897 - val_loss: 0.4775 - val_accuracy: 0.7733\n",
      "Epoch 68/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7878 - val_loss: 0.4770 - val_accuracy: 0.7778\n",
      "Epoch 69/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7878 - val_loss: 0.4764 - val_accuracy: 0.7822\n",
      "Epoch 70/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7820 - val_loss: 0.4772 - val_accuracy: 0.7778\n",
      "Epoch 71/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7859 - val_loss: 0.4762 - val_accuracy: 0.7822\n",
      "Epoch 72/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7859 - val_loss: 0.4758 - val_accuracy: 0.7822\n",
      "Epoch 73/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7839 - val_loss: 0.4754 - val_accuracy: 0.7778\n",
      "Epoch 74/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7897 - val_loss: 0.4744 - val_accuracy: 0.7822\n",
      "Epoch 75/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7897 - val_loss: 0.4756 - val_accuracy: 0.7778\n",
      "Epoch 76/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4625 - accuracy: 0.7916 - val_loss: 0.4754 - val_accuracy: 0.7778\n",
      "Epoch 77/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7782 - val_loss: 0.4748 - val_accuracy: 0.7778\n",
      "Epoch 78/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4755 - accuracy: 0.7839 - val_loss: 0.4743 - val_accuracy: 0.7822\n",
      "Epoch 79/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4699 - accuracy: 0.7859 - val_loss: 0.4747 - val_accuracy: 0.7822\n",
      "Epoch 80/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.7763 - val_loss: 0.4752 - val_accuracy: 0.7778\n",
      "Epoch 81/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7839 - val_loss: 0.4745 - val_accuracy: 0.7822\n",
      "Epoch 82/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4723 - accuracy: 0.7839 - val_loss: 0.4739 - val_accuracy: 0.7822\n",
      "Epoch 83/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7878 - val_loss: 0.4748 - val_accuracy: 0.7778\n",
      "Epoch 84/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7897 - val_loss: 0.4741 - val_accuracy: 0.7778\n",
      "Epoch 85/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7820 - val_loss: 0.4749 - val_accuracy: 0.7822\n",
      "Epoch 86/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7820 - val_loss: 0.4740 - val_accuracy: 0.7778\n",
      "Epoch 87/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7801 - val_loss: 0.4753 - val_accuracy: 0.7689\n",
      "Epoch 88/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7935 - val_loss: 0.4723 - val_accuracy: 0.7822\n",
      "Epoch 89/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7897 - val_loss: 0.4725 - val_accuracy: 0.7778\n",
      "Epoch 90/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7897 - val_loss: 0.4724 - val_accuracy: 0.7778\n",
      "Epoch 91/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7839 - val_loss: 0.4730 - val_accuracy: 0.7778\n",
      "Epoch 92/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7935 - val_loss: 0.4725 - val_accuracy: 0.7778\n",
      "Epoch 93/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7820 - val_loss: 0.4714 - val_accuracy: 0.7822\n",
      "Epoch 94/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7763 - val_loss: 0.4706 - val_accuracy: 0.7867\n",
      "Epoch 95/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7839 - val_loss: 0.4721 - val_accuracy: 0.7822\n",
      "Epoch 96/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7916 - val_loss: 0.4721 - val_accuracy: 0.7822\n",
      "Epoch 97/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7897 - val_loss: 0.4711 - val_accuracy: 0.7867\n",
      "Epoch 98/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7839 - val_loss: 0.4721 - val_accuracy: 0.7778\n",
      "Epoch 99/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7839 - val_loss: 0.4721 - val_accuracy: 0.7778\n",
      "Epoch 100/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7954 - val_loss: 0.4707 - val_accuracy: 0.7867\n",
      "Epoch 101/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7916 - val_loss: 0.4719 - val_accuracy: 0.7822\n",
      "Epoch 102/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7897 - val_loss: 0.4710 - val_accuracy: 0.7867\n",
      "Epoch 103/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7839 - val_loss: 0.4699 - val_accuracy: 0.7911\n",
      "Epoch 104/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7706 - val_loss: 0.4710 - val_accuracy: 0.7867\n",
      "Epoch 105/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7782 - val_loss: 0.4717 - val_accuracy: 0.7822\n",
      "Epoch 106/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7859 - val_loss: 0.4707 - val_accuracy: 0.7822\n",
      "Epoch 107/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4685 - accuracy: 0.7820 - val_loss: 0.4700 - val_accuracy: 0.7867\n",
      "Epoch 108/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4681 - accuracy: 0.7801 - val_loss: 0.4689 - val_accuracy: 0.7867\n",
      "Epoch 109/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7954 - val_loss: 0.4710 - val_accuracy: 0.7778\n",
      "Epoch 110/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7859 - val_loss: 0.4684 - val_accuracy: 0.7867\n",
      "Epoch 111/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7859 - val_loss: 0.4677 - val_accuracy: 0.7867\n",
      "Epoch 112/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4637 - accuracy: 0.7820 - val_loss: 0.4683 - val_accuracy: 0.7911\n",
      "Epoch 113/1600\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.4650 - accuracy: 0.7878 - val_loss: 0.4682 - val_accuracy: 0.7867\n",
      "Epoch 114/1600\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.4666 - accuracy: 0.7878 - val_loss: 0.4686 - val_accuracy: 0.7867\n",
      "Epoch 115/1600\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.4624 - accuracy: 0.7897 - val_loss: 0.4682 - val_accuracy: 0.7911\n",
      "Epoch 116/1600\n",
      "17/17 [==============================] - 1s 48ms/step - loss: 0.4551 - accuracy: 0.7878 - val_loss: 0.4684 - val_accuracy: 0.7911\n",
      "Epoch 117/1600\n",
      "17/17 [==============================] - 1s 47ms/step - loss: 0.4645 - accuracy: 0.7935 - val_loss: 0.4677 - val_accuracy: 0.7867\n",
      "Epoch 118/1600\n",
      "17/17 [==============================] - 1s 36ms/step - loss: 0.4663 - accuracy: 0.7954 - val_loss: 0.4670 - val_accuracy: 0.7867\n",
      "Epoch 119/1600\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4637 - accuracy: 0.7859 - val_loss: 0.4689 - val_accuracy: 0.7867\n",
      "Epoch 120/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7878 - val_loss: 0.4677 - val_accuracy: 0.7867\n",
      "Epoch 121/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7954 - val_loss: 0.4667 - val_accuracy: 0.7911\n",
      "Epoch 122/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4694 - accuracy: 0.7859 - val_loss: 0.4674 - val_accuracy: 0.7867\n",
      "Epoch 123/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4612 - accuracy: 0.7839 - val_loss: 0.4678 - val_accuracy: 0.7911\n",
      "Epoch 124/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4641 - accuracy: 0.7820 - val_loss: 0.4675 - val_accuracy: 0.7867\n",
      "Epoch 125/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4647 - accuracy: 0.7935 - val_loss: 0.4694 - val_accuracy: 0.7911\n",
      "Epoch 126/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4713 - accuracy: 0.7897 - val_loss: 0.4677 - val_accuracy: 0.7911\n",
      "Epoch 127/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4616 - accuracy: 0.7878 - val_loss: 0.4678 - val_accuracy: 0.7911\n",
      "Epoch 128/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4699 - accuracy: 0.7839 - val_loss: 0.4675 - val_accuracy: 0.7911\n",
      "Epoch 129/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4649 - accuracy: 0.7916 - val_loss: 0.4668 - val_accuracy: 0.7911\n",
      "Epoch 130/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4645 - accuracy: 0.7820 - val_loss: 0.4661 - val_accuracy: 0.7911\n",
      "Epoch 131/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.8088 - val_loss: 0.4667 - val_accuracy: 0.7956\n",
      "Epoch 132/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7878 - val_loss: 0.4662 - val_accuracy: 0.7956\n",
      "Epoch 133/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7916 - val_loss: 0.4671 - val_accuracy: 0.7911\n",
      "Epoch 134/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4626 - accuracy: 0.7878 - val_loss: 0.4669 - val_accuracy: 0.7911\n",
      "Epoch 135/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4642 - accuracy: 0.7878 - val_loss: 0.4658 - val_accuracy: 0.7956\n",
      "Epoch 136/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4595 - accuracy: 0.7973 - val_loss: 0.4667 - val_accuracy: 0.7911\n",
      "Epoch 137/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7744 - val_loss: 0.4671 - val_accuracy: 0.7956\n",
      "Epoch 138/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4647 - accuracy: 0.7954 - val_loss: 0.4669 - val_accuracy: 0.7911\n",
      "Epoch 139/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4632 - accuracy: 0.7935 - val_loss: 0.4671 - val_accuracy: 0.7911\n",
      "Epoch 140/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4720 - accuracy: 0.7801 - val_loss: 0.4667 - val_accuracy: 0.7956\n",
      "Epoch 141/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4644 - accuracy: 0.7878 - val_loss: 0.4665 - val_accuracy: 0.7956\n",
      "Epoch 142/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4629 - accuracy: 0.7878 - val_loss: 0.4671 - val_accuracy: 0.7911\n",
      "Epoch 143/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4691 - accuracy: 0.7878 - val_loss: 0.4672 - val_accuracy: 0.7956\n",
      "Epoch 144/1600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4645 - accuracy: 0.7820 - val_loss: 0.4670 - val_accuracy: 0.7911\n",
      "Epoch 145/1600\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.4610 - accuracy: 0.7782 - val_loss: 0.4664 - val_accuracy: 0.7911\n",
      "Epoch 146/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4620 - accuracy: 0.7897 - val_loss: 0.4674 - val_accuracy: 0.7911\n",
      "Epoch 147/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4583 - accuracy: 0.7916 - val_loss: 0.4667 - val_accuracy: 0.7956\n",
      "Epoch 148/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4633 - accuracy: 0.7916 - val_loss: 0.4674 - val_accuracy: 0.7956\n",
      "Epoch 149/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4637 - accuracy: 0.7839 - val_loss: 0.4688 - val_accuracy: 0.7867\n",
      "Epoch 150/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4719 - accuracy: 0.7763 - val_loss: 0.4674 - val_accuracy: 0.7911\n",
      "Epoch 151/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4634 - accuracy: 0.7897 - val_loss: 0.4669 - val_accuracy: 0.7956\n",
      "Epoch 152/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4655 - accuracy: 0.7878 - val_loss: 0.4660 - val_accuracy: 0.7911\n",
      "Epoch 153/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4638 - accuracy: 0.7916 - val_loss: 0.4672 - val_accuracy: 0.7911\n",
      "Epoch 154/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4622 - accuracy: 0.7897 - val_loss: 0.4673 - val_accuracy: 0.7956\n",
      "Epoch 155/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4633 - accuracy: 0.7820 - val_loss: 0.4668 - val_accuracy: 0.7956\n",
      "Epoch 156/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4617 - accuracy: 0.7935 - val_loss: 0.4683 - val_accuracy: 0.7867\n",
      "Epoch 157/1600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4670 - accuracy: 0.7839 - val_loss: 0.4664 - val_accuracy: 0.7956\n",
      "Epoch 158/1600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4623 - accuracy: 0.7916 - val_loss: 0.4675 - val_accuracy: 0.7956\n",
      "Epoch 159/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4614 - accuracy: 0.7935 - val_loss: 0.4678 - val_accuracy: 0.7867\n",
      "Epoch 160/1600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4662 - accuracy: 0.7954 - val_loss: 0.4668 - val_accuracy: 0.7911\n",
      "Epoch 161/1600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.4625 - accuracy: 0.7897 - val_loss: 0.4664 - val_accuracy: 0.7956\n",
      "Epoch 162/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4655 - accuracy: 0.7916 - val_loss: 0.4666 - val_accuracy: 0.7911\n",
      "Epoch 163/1600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4639 - accuracy: 0.7839 - val_loss: 0.4667 - val_accuracy: 0.7911\n",
      "Epoch 164/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4622 - accuracy: 0.7820 - val_loss: 0.4670 - val_accuracy: 0.7911\n",
      "Epoch 165/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4615 - accuracy: 0.7878 - val_loss: 0.4671 - val_accuracy: 0.7911\n",
      "Epoch 166/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4622 - accuracy: 0.7859 - val_loss: 0.4667 - val_accuracy: 0.7956\n",
      "Epoch 167/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4597 - accuracy: 0.7878 - val_loss: 0.4659 - val_accuracy: 0.7911\n",
      "Epoch 168/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.7878 - val_loss: 0.4688 - val_accuracy: 0.7867\n",
      "Epoch 169/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4606 - accuracy: 0.7820 - val_loss: 0.4653 - val_accuracy: 0.8000\n",
      "Epoch 170/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.7916 - val_loss: 0.4656 - val_accuracy: 0.7911\n",
      "Epoch 171/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7820 - val_loss: 0.4652 - val_accuracy: 0.7911\n",
      "Epoch 172/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4590 - accuracy: 0.7954 - val_loss: 0.4648 - val_accuracy: 0.7956\n",
      "Epoch 173/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4655 - accuracy: 0.7878 - val_loss: 0.4645 - val_accuracy: 0.7956\n",
      "Epoch 174/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4627 - accuracy: 0.7839 - val_loss: 0.4652 - val_accuracy: 0.7956\n",
      "Epoch 175/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7878 - val_loss: 0.4670 - val_accuracy: 0.7911\n",
      "Epoch 176/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7878 - val_loss: 0.4670 - val_accuracy: 0.7956\n",
      "Epoch 177/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7782 - val_loss: 0.4655 - val_accuracy: 0.7956\n",
      "Epoch 178/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4609 - accuracy: 0.7839 - val_loss: 0.4679 - val_accuracy: 0.7911\n",
      "Epoch 179/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7973 - val_loss: 0.4662 - val_accuracy: 0.7911\n",
      "Epoch 180/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4633 - accuracy: 0.7839 - val_loss: 0.4653 - val_accuracy: 0.7956\n",
      "Epoch 181/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4632 - accuracy: 0.7954 - val_loss: 0.4655 - val_accuracy: 0.7956\n",
      "Epoch 182/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4605 - accuracy: 0.7916 - val_loss: 0.4635 - val_accuracy: 0.8000\n",
      "Epoch 183/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4668 - accuracy: 0.7801 - val_loss: 0.4648 - val_accuracy: 0.7911\n",
      "Epoch 184/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4667 - accuracy: 0.7878 - val_loss: 0.4645 - val_accuracy: 0.7956\n",
      "Epoch 185/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4642 - accuracy: 0.7897 - val_loss: 0.4639 - val_accuracy: 0.7956\n",
      "Epoch 186/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4635 - accuracy: 0.7954 - val_loss: 0.4649 - val_accuracy: 0.7956\n",
      "Epoch 187/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7859 - val_loss: 0.4652 - val_accuracy: 0.7956\n",
      "Epoch 188/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7897 - val_loss: 0.4648 - val_accuracy: 0.7956\n",
      "Epoch 189/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.7839 - val_loss: 0.4654 - val_accuracy: 0.7956\n",
      "Epoch 190/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7839 - val_loss: 0.4634 - val_accuracy: 0.8044\n",
      "Epoch 191/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.8011 - val_loss: 0.4639 - val_accuracy: 0.7956\n",
      "Epoch 192/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7878 - val_loss: 0.4636 - val_accuracy: 0.8000\n",
      "Epoch 193/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7859 - val_loss: 0.4641 - val_accuracy: 0.7911\n",
      "Epoch 194/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7859 - val_loss: 0.4646 - val_accuracy: 0.7956\n",
      "Epoch 195/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7897 - val_loss: 0.4632 - val_accuracy: 0.8000\n",
      "Epoch 196/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7954 - val_loss: 0.4631 - val_accuracy: 0.8044\n",
      "Epoch 197/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7820 - val_loss: 0.4631 - val_accuracy: 0.7956\n",
      "Epoch 198/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.8031 - val_loss: 0.4624 - val_accuracy: 0.8000\n",
      "Epoch 199/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7897 - val_loss: 0.4628 - val_accuracy: 0.8044\n",
      "Epoch 200/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7820 - val_loss: 0.4654 - val_accuracy: 0.7956\n",
      "Epoch 201/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7801 - val_loss: 0.4644 - val_accuracy: 0.8000\n",
      "Epoch 202/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7782 - val_loss: 0.4637 - val_accuracy: 0.8044\n",
      "Epoch 203/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7839 - val_loss: 0.4636 - val_accuracy: 0.8044\n",
      "Epoch 204/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7839 - val_loss: 0.4634 - val_accuracy: 0.7956\n",
      "Epoch 205/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7954 - val_loss: 0.4635 - val_accuracy: 0.8044\n",
      "Epoch 206/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7839 - val_loss: 0.4635 - val_accuracy: 0.8000\n",
      "Epoch 207/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7916 - val_loss: 0.4624 - val_accuracy: 0.8000\n",
      "Epoch 208/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4615 - accuracy: 0.7916 - val_loss: 0.4624 - val_accuracy: 0.8044\n",
      "Epoch 209/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4642 - accuracy: 0.7820 - val_loss: 0.4623 - val_accuracy: 0.7956\n",
      "Epoch 210/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7820 - val_loss: 0.4628 - val_accuracy: 0.7956\n",
      "Epoch 211/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4611 - accuracy: 0.7859 - val_loss: 0.4646 - val_accuracy: 0.7911\n",
      "Epoch 212/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4631 - accuracy: 0.7820 - val_loss: 0.4635 - val_accuracy: 0.8000\n",
      "Epoch 213/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4638 - accuracy: 0.7897 - val_loss: 0.4633 - val_accuracy: 0.7956\n",
      "Epoch 214/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4559 - accuracy: 0.7878 - val_loss: 0.4629 - val_accuracy: 0.8000\n",
      "Epoch 215/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7801 - val_loss: 0.4627 - val_accuracy: 0.7956\n",
      "Epoch 216/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4624 - accuracy: 0.7916 - val_loss: 0.4640 - val_accuracy: 0.7956\n",
      "Epoch 217/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4618 - accuracy: 0.7916 - val_loss: 0.4614 - val_accuracy: 0.8000\n",
      "Epoch 218/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4636 - accuracy: 0.7973 - val_loss: 0.4603 - val_accuracy: 0.8089\n",
      "Epoch 219/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4637 - accuracy: 0.7820 - val_loss: 0.4619 - val_accuracy: 0.8000\n",
      "Epoch 220/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4649 - accuracy: 0.7801 - val_loss: 0.4645 - val_accuracy: 0.8000\n",
      "Epoch 221/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4575 - accuracy: 0.7859 - val_loss: 0.4623 - val_accuracy: 0.8044\n",
      "Epoch 222/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4553 - accuracy: 0.7973 - val_loss: 0.4618 - val_accuracy: 0.8089\n",
      "Epoch 223/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4597 - accuracy: 0.7782 - val_loss: 0.4621 - val_accuracy: 0.8000\n",
      "Epoch 224/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7954 - val_loss: 0.4619 - val_accuracy: 0.8000\n",
      "Epoch 225/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7973 - val_loss: 0.4626 - val_accuracy: 0.8044\n",
      "Epoch 226/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7916 - val_loss: 0.4627 - val_accuracy: 0.8089\n",
      "Epoch 227/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.8050 - val_loss: 0.4629 - val_accuracy: 0.8044\n",
      "Epoch 228/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.7992 - val_loss: 0.4615 - val_accuracy: 0.8089\n",
      "Epoch 229/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4557 - accuracy: 0.7916 - val_loss: 0.4617 - val_accuracy: 0.8000\n",
      "Epoch 230/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4579 - accuracy: 0.7954 - val_loss: 0.4624 - val_accuracy: 0.8044\n",
      "Epoch 231/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4598 - accuracy: 0.7878 - val_loss: 0.4628 - val_accuracy: 0.8000\n",
      "Epoch 232/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4586 - accuracy: 0.7954 - val_loss: 0.4616 - val_accuracy: 0.8000\n",
      "Epoch 233/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7916 - val_loss: 0.4631 - val_accuracy: 0.8000\n",
      "Epoch 234/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4568 - accuracy: 0.7973 - val_loss: 0.4653 - val_accuracy: 0.8000\n",
      "Epoch 235/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7782 - val_loss: 0.4625 - val_accuracy: 0.7956\n",
      "Epoch 236/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4546 - accuracy: 0.7954 - val_loss: 0.4621 - val_accuracy: 0.8000\n",
      "Epoch 237/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4613 - accuracy: 0.7878 - val_loss: 0.4601 - val_accuracy: 0.8000\n",
      "Epoch 238/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4604 - accuracy: 0.7954 - val_loss: 0.4596 - val_accuracy: 0.8000\n",
      "Epoch 239/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4591 - accuracy: 0.7916 - val_loss: 0.4609 - val_accuracy: 0.8000\n",
      "Epoch 240/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4534 - accuracy: 0.7973 - val_loss: 0.4613 - val_accuracy: 0.8089\n",
      "Epoch 241/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4530 - accuracy: 0.7878 - val_loss: 0.4619 - val_accuracy: 0.8000\n",
      "Epoch 242/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4566 - accuracy: 0.7954 - val_loss: 0.4614 - val_accuracy: 0.8000\n",
      "Epoch 243/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.8031 - val_loss: 0.4591 - val_accuracy: 0.8133\n",
      "Epoch 244/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4693 - accuracy: 0.7897 - val_loss: 0.4598 - val_accuracy: 0.8000\n",
      "Epoch 245/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4615 - accuracy: 0.7878 - val_loss: 0.4605 - val_accuracy: 0.8000\n",
      "Epoch 246/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4613 - accuracy: 0.7897 - val_loss: 0.4602 - val_accuracy: 0.8000\n",
      "Epoch 247/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.7859 - val_loss: 0.4603 - val_accuracy: 0.8000\n",
      "Epoch 248/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4575 - accuracy: 0.7973 - val_loss: 0.4606 - val_accuracy: 0.8000\n",
      "Epoch 249/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7801 - val_loss: 0.4603 - val_accuracy: 0.8044\n",
      "Epoch 250/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4642 - accuracy: 0.7954 - val_loss: 0.4605 - val_accuracy: 0.8000\n",
      "Epoch 251/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4626 - accuracy: 0.7954 - val_loss: 0.4595 - val_accuracy: 0.8000\n",
      "Epoch 252/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4618 - accuracy: 0.7839 - val_loss: 0.4598 - val_accuracy: 0.8089\n",
      "Epoch 253/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4614 - accuracy: 0.8050 - val_loss: 0.4626 - val_accuracy: 0.8044\n",
      "Epoch 254/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7859 - val_loss: 0.4637 - val_accuracy: 0.8089\n",
      "Epoch 255/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4586 - accuracy: 0.7992 - val_loss: 0.4606 - val_accuracy: 0.8044\n",
      "Epoch 256/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4612 - accuracy: 0.7954 - val_loss: 0.4599 - val_accuracy: 0.8000\n",
      "Epoch 257/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4616 - accuracy: 0.7897 - val_loss: 0.4601 - val_accuracy: 0.8000\n",
      "Epoch 258/1600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4557 - accuracy: 0.8011 - val_loss: 0.4601 - val_accuracy: 0.8000\n",
      "Epoch 259/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4628 - accuracy: 0.7878 - val_loss: 0.4605 - val_accuracy: 0.8000\n",
      "Epoch 260/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4602 - accuracy: 0.7820 - val_loss: 0.4620 - val_accuracy: 0.8000\n",
      "Epoch 261/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4556 - accuracy: 0.7897 - val_loss: 0.4595 - val_accuracy: 0.8044\n",
      "Epoch 262/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4576 - accuracy: 0.7954 - val_loss: 0.4600 - val_accuracy: 0.8044\n",
      "Epoch 263/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.7935 - val_loss: 0.4604 - val_accuracy: 0.8000\n",
      "Epoch 264/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4637 - accuracy: 0.7782 - val_loss: 0.4598 - val_accuracy: 0.8044\n",
      "Epoch 265/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4547 - accuracy: 0.7954 - val_loss: 0.4602 - val_accuracy: 0.8089\n",
      "Epoch 266/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4645 - accuracy: 0.7839 - val_loss: 0.4587 - val_accuracy: 0.8133\n",
      "Epoch 267/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.7973 - val_loss: 0.4603 - val_accuracy: 0.8000\n",
      "Epoch 268/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.7916 - val_loss: 0.4584 - val_accuracy: 0.8044\n",
      "Epoch 269/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4520 - accuracy: 0.7992 - val_loss: 0.4581 - val_accuracy: 0.8089\n",
      "Epoch 270/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4644 - accuracy: 0.7839 - val_loss: 0.4583 - val_accuracy: 0.8133\n",
      "Epoch 271/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4516 - accuracy: 0.7954 - val_loss: 0.4582 - val_accuracy: 0.8089\n",
      "Epoch 272/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4581 - accuracy: 0.8069 - val_loss: 0.4567 - val_accuracy: 0.8089\n",
      "Epoch 273/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4595 - accuracy: 0.7859 - val_loss: 0.4590 - val_accuracy: 0.8000\n",
      "Epoch 274/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4594 - accuracy: 0.7859 - val_loss: 0.4577 - val_accuracy: 0.8044\n",
      "Epoch 275/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4549 - accuracy: 0.7954 - val_loss: 0.4600 - val_accuracy: 0.8000\n",
      "Epoch 276/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4558 - accuracy: 0.8031 - val_loss: 0.4606 - val_accuracy: 0.8089\n",
      "Epoch 277/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4573 - accuracy: 0.7954 - val_loss: 0.4601 - val_accuracy: 0.8089\n",
      "Epoch 278/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4574 - accuracy: 0.7935 - val_loss: 0.4606 - val_accuracy: 0.8044\n",
      "Epoch 279/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4580 - accuracy: 0.7916 - val_loss: 0.4594 - val_accuracy: 0.8000\n",
      "Epoch 280/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4573 - accuracy: 0.7839 - val_loss: 0.4582 - val_accuracy: 0.8044\n",
      "Epoch 281/1600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4578 - accuracy: 0.7992 - val_loss: 0.4577 - val_accuracy: 0.8044\n",
      "Epoch 282/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4538 - accuracy: 0.7897 - val_loss: 0.4585 - val_accuracy: 0.8089\n",
      "Epoch 283/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4632 - accuracy: 0.7859 - val_loss: 0.4574 - val_accuracy: 0.8044\n",
      "Epoch 284/1600\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.4543 - accuracy: 0.7897 - val_loss: 0.4574 - val_accuracy: 0.8044\n",
      "Epoch 285/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4558 - accuracy: 0.7859 - val_loss: 0.4576 - val_accuracy: 0.8044\n",
      "Epoch 286/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4618 - accuracy: 0.7859 - val_loss: 0.4575 - val_accuracy: 0.8044\n",
      "Epoch 287/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4569 - accuracy: 0.7935 - val_loss: 0.4572 - val_accuracy: 0.8089\n",
      "Epoch 288/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4590 - accuracy: 0.7973 - val_loss: 0.4593 - val_accuracy: 0.8089\n",
      "Epoch 289/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4558 - accuracy: 0.7859 - val_loss: 0.4589 - val_accuracy: 0.8000\n",
      "Epoch 290/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4610 - accuracy: 0.7916 - val_loss: 0.4594 - val_accuracy: 0.8000\n",
      "Epoch 291/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4589 - accuracy: 0.8011 - val_loss: 0.4578 - val_accuracy: 0.8089\n",
      "Epoch 292/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4598 - accuracy: 0.7897 - val_loss: 0.4570 - val_accuracy: 0.8044\n",
      "Epoch 293/1600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4592 - accuracy: 0.7973 - val_loss: 0.4571 - val_accuracy: 0.8044\n",
      "Epoch 294/1600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4589 - accuracy: 0.7897 - val_loss: 0.4581 - val_accuracy: 0.8044\n",
      "Epoch 295/1600\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.4582 - accuracy: 0.7935 - val_loss: 0.4589 - val_accuracy: 0.8089\n",
      "Epoch 296/1600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4611 - accuracy: 0.7897 - val_loss: 0.4593 - val_accuracy: 0.8089\n",
      "Epoch 297/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4570 - accuracy: 0.7897 - val_loss: 0.4605 - val_accuracy: 0.8089\n",
      "Epoch 298/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4537 - accuracy: 0.7992 - val_loss: 0.4606 - val_accuracy: 0.8000\n",
      "Epoch 299/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4552 - accuracy: 0.7954 - val_loss: 0.4583 - val_accuracy: 0.8133\n",
      "Epoch 300/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4623 - accuracy: 0.7973 - val_loss: 0.4591 - val_accuracy: 0.8044\n",
      "Epoch 301/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4606 - accuracy: 0.8031 - val_loss: 0.4578 - val_accuracy: 0.8089\n",
      "Epoch 302/1600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.4551 - accuracy: 0.8031 - val_loss: 0.4585 - val_accuracy: 0.8089\n",
      "Epoch 303/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.7973 - val_loss: 0.4591 - val_accuracy: 0.8089\n",
      "Epoch 304/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7859 - val_loss: 0.4582 - val_accuracy: 0.8089\n",
      "Epoch 305/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4574 - accuracy: 0.7916 - val_loss: 0.4553 - val_accuracy: 0.8178\n",
      "Epoch 306/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4620 - accuracy: 0.7859 - val_loss: 0.4599 - val_accuracy: 0.8000\n",
      "Epoch 307/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.7859 - val_loss: 0.4575 - val_accuracy: 0.8044\n",
      "Epoch 308/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.8011 - val_loss: 0.4569 - val_accuracy: 0.8089\n",
      "Epoch 309/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.8011 - val_loss: 0.4570 - val_accuracy: 0.8044\n",
      "Epoch 310/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4578 - accuracy: 0.7897 - val_loss: 0.4584 - val_accuracy: 0.8133\n",
      "Epoch 311/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4569 - accuracy: 0.7935 - val_loss: 0.4580 - val_accuracy: 0.8133\n",
      "Epoch 312/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4535 - accuracy: 0.8050 - val_loss: 0.4579 - val_accuracy: 0.8089\n",
      "Epoch 313/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4626 - accuracy: 0.7878 - val_loss: 0.4586 - val_accuracy: 0.8089\n",
      "Epoch 314/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4547 - accuracy: 0.8031 - val_loss: 0.4593 - val_accuracy: 0.8089\n",
      "Epoch 315/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4523 - accuracy: 0.8031 - val_loss: 0.4595 - val_accuracy: 0.8089\n",
      "Epoch 316/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7935 - val_loss: 0.4594 - val_accuracy: 0.8133\n",
      "Epoch 317/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7992 - val_loss: 0.4579 - val_accuracy: 0.8089\n",
      "Epoch 318/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4505 - accuracy: 0.7973 - val_loss: 0.4578 - val_accuracy: 0.8089\n",
      "Epoch 319/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7973 - val_loss: 0.4584 - val_accuracy: 0.8089\n",
      "Epoch 320/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7992 - val_loss: 0.4560 - val_accuracy: 0.8089\n",
      "Epoch 321/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4495 - accuracy: 0.8011 - val_loss: 0.4583 - val_accuracy: 0.8089\n",
      "Epoch 322/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.7973 - val_loss: 0.4578 - val_accuracy: 0.8089\n",
      "Epoch 323/1600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4598 - accuracy: 0.7992 - val_loss: 0.4597 - val_accuracy: 0.8133\n",
      "Epoch 324/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4523 - accuracy: 0.7954 - val_loss: 0.4620 - val_accuracy: 0.8000\n",
      "Epoch 325/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4555 - accuracy: 0.8011 - val_loss: 0.4581 - val_accuracy: 0.8089\n",
      "Epoch 326/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4573 - accuracy: 0.7916 - val_loss: 0.4595 - val_accuracy: 0.8089\n",
      "Epoch 327/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4509 - accuracy: 0.7992 - val_loss: 0.4561 - val_accuracy: 0.8133\n",
      "Epoch 328/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.7935 - val_loss: 0.4579 - val_accuracy: 0.8133\n",
      "Epoch 329/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7897 - val_loss: 0.4580 - val_accuracy: 0.8089\n",
      "Epoch 330/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.8011 - val_loss: 0.4572 - val_accuracy: 0.8178\n",
      "Epoch 331/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7916 - val_loss: 0.4589 - val_accuracy: 0.8089\n",
      "Epoch 332/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.8088 - val_loss: 0.4569 - val_accuracy: 0.8044\n",
      "Epoch 333/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.8031 - val_loss: 0.4572 - val_accuracy: 0.8089\n",
      "Epoch 334/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4570 - accuracy: 0.7878 - val_loss: 0.4571 - val_accuracy: 0.8044\n",
      "Epoch 335/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4573 - accuracy: 0.7973 - val_loss: 0.4579 - val_accuracy: 0.8044\n",
      "Epoch 336/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4548 - accuracy: 0.8031 - val_loss: 0.4585 - val_accuracy: 0.8089\n",
      "Epoch 337/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.8011 - val_loss: 0.4557 - val_accuracy: 0.8089\n",
      "Epoch 338/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4550 - accuracy: 0.7878 - val_loss: 0.4545 - val_accuracy: 0.8133\n",
      "Epoch 339/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7954 - val_loss: 0.4560 - val_accuracy: 0.8133\n",
      "Epoch 340/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7859 - val_loss: 0.4565 - val_accuracy: 0.8044\n",
      "Epoch 341/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7916 - val_loss: 0.4568 - val_accuracy: 0.8044\n",
      "Epoch 342/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.7801 - val_loss: 0.4581 - val_accuracy: 0.8044\n",
      "Epoch 343/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7916 - val_loss: 0.4585 - val_accuracy: 0.8089\n",
      "Epoch 344/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7878 - val_loss: 0.4574 - val_accuracy: 0.8044\n",
      "Epoch 345/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7954 - val_loss: 0.4567 - val_accuracy: 0.8044\n",
      "Epoch 346/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4555 - accuracy: 0.7992 - val_loss: 0.4542 - val_accuracy: 0.8089\n",
      "Epoch 347/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7935 - val_loss: 0.4551 - val_accuracy: 0.8044\n",
      "Epoch 348/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.8050 - val_loss: 0.4529 - val_accuracy: 0.8089\n",
      "Epoch 349/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7954 - val_loss: 0.4558 - val_accuracy: 0.8089\n",
      "Epoch 350/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7973 - val_loss: 0.4550 - val_accuracy: 0.8044\n",
      "Epoch 351/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7992 - val_loss: 0.4574 - val_accuracy: 0.8089\n",
      "Epoch 352/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7954 - val_loss: 0.4565 - val_accuracy: 0.8178\n",
      "Epoch 353/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7973 - val_loss: 0.4564 - val_accuracy: 0.8089\n",
      "Epoch 354/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7954 - val_loss: 0.4560 - val_accuracy: 0.8044\n",
      "Epoch 355/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.8088 - val_loss: 0.4548 - val_accuracy: 0.8089\n",
      "Epoch 356/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7897 - val_loss: 0.4563 - val_accuracy: 0.8044\n",
      "Epoch 357/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4556 - accuracy: 0.7992 - val_loss: 0.4565 - val_accuracy: 0.8044\n",
      "Epoch 358/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.8031 - val_loss: 0.4571 - val_accuracy: 0.8089\n",
      "Epoch 359/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4524 - accuracy: 0.8011 - val_loss: 0.4573 - val_accuracy: 0.8133\n",
      "Epoch 360/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4551 - accuracy: 0.7954 - val_loss: 0.4550 - val_accuracy: 0.8044\n",
      "Epoch 361/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7859 - val_loss: 0.4553 - val_accuracy: 0.8089\n",
      "Epoch 362/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4566 - accuracy: 0.7954 - val_loss: 0.4559 - val_accuracy: 0.8044\n",
      "Epoch 363/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7801 - val_loss: 0.4604 - val_accuracy: 0.8089\n",
      "Epoch 364/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7916 - val_loss: 0.4575 - val_accuracy: 0.8044\n",
      "Epoch 365/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7859 - val_loss: 0.4571 - val_accuracy: 0.8089\n",
      "Epoch 366/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.8050 - val_loss: 0.4584 - val_accuracy: 0.8089\n",
      "Epoch 367/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.8011 - val_loss: 0.4567 - val_accuracy: 0.8089\n",
      "Epoch 368/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7782 - val_loss: 0.4570 - val_accuracy: 0.8133\n",
      "Epoch 369/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.8031 - val_loss: 0.4584 - val_accuracy: 0.8089\n",
      "Epoch 370/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4533 - accuracy: 0.7992 - val_loss: 0.4584 - val_accuracy: 0.8089\n",
      "Epoch 371/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4547 - accuracy: 0.7954 - val_loss: 0.4602 - val_accuracy: 0.8089\n",
      "Epoch 372/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4595 - accuracy: 0.7954 - val_loss: 0.4575 - val_accuracy: 0.8089\n",
      "Epoch 373/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7916 - val_loss: 0.4571 - val_accuracy: 0.8089\n",
      "Epoch 374/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.8011 - val_loss: 0.4558 - val_accuracy: 0.8044\n",
      "Epoch 375/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4567 - accuracy: 0.7859 - val_loss: 0.4589 - val_accuracy: 0.8089\n",
      "Epoch 376/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4553 - accuracy: 0.7992 - val_loss: 0.4594 - val_accuracy: 0.8089\n",
      "Epoch 377/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4566 - accuracy: 0.7878 - val_loss: 0.4592 - val_accuracy: 0.8089\n",
      "Epoch 378/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4593 - accuracy: 0.7859 - val_loss: 0.4575 - val_accuracy: 0.8044\n",
      "Epoch 379/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4568 - accuracy: 0.7992 - val_loss: 0.4634 - val_accuracy: 0.7956\n",
      "Epoch 380/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.7992 - val_loss: 0.4584 - val_accuracy: 0.8044\n",
      "Epoch 381/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4518 - accuracy: 0.8011 - val_loss: 0.4617 - val_accuracy: 0.7956\n",
      "Epoch 382/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4629 - accuracy: 0.7973 - val_loss: 0.4591 - val_accuracy: 0.8089\n",
      "Epoch 383/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4558 - accuracy: 0.8050 - val_loss: 0.4614 - val_accuracy: 0.8089\n",
      "Epoch 384/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4588 - accuracy: 0.7954 - val_loss: 0.4599 - val_accuracy: 0.8089\n",
      "Epoch 385/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4526 - accuracy: 0.7992 - val_loss: 0.4578 - val_accuracy: 0.8089\n",
      "Epoch 386/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4535 - accuracy: 0.7935 - val_loss: 0.4579 - val_accuracy: 0.8089\n",
      "Epoch 387/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4562 - accuracy: 0.8031 - val_loss: 0.4572 - val_accuracy: 0.8133\n",
      "Epoch 388/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4558 - accuracy: 0.7916 - val_loss: 0.4584 - val_accuracy: 0.8089\n",
      "Epoch 389/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4604 - accuracy: 0.7916 - val_loss: 0.4565 - val_accuracy: 0.8089\n",
      "Epoch 390/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7916 - val_loss: 0.4581 - val_accuracy: 0.8089\n",
      "Epoch 391/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4537 - accuracy: 0.7973 - val_loss: 0.4576 - val_accuracy: 0.8044\n",
      "Epoch 392/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4536 - accuracy: 0.7954 - val_loss: 0.4579 - val_accuracy: 0.8044\n",
      "Epoch 393/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.7916 - val_loss: 0.4582 - val_accuracy: 0.8089\n",
      "Epoch 394/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7954 - val_loss: 0.4595 - val_accuracy: 0.8089\n",
      "Epoch 395/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4552 - accuracy: 0.8050 - val_loss: 0.4601 - val_accuracy: 0.8044\n",
      "Epoch 396/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7954 - val_loss: 0.4596 - val_accuracy: 0.8089\n",
      "Epoch 397/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4486 - accuracy: 0.7935 - val_loss: 0.4587 - val_accuracy: 0.8089\n",
      "Epoch 398/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4476 - accuracy: 0.8069 - val_loss: 0.4576 - val_accuracy: 0.8044\n",
      "Epoch 399/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4574 - accuracy: 0.8031 - val_loss: 0.4577 - val_accuracy: 0.8089\n",
      "Epoch 400/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4537 - accuracy: 0.7935 - val_loss: 0.4583 - val_accuracy: 0.8089\n",
      "Epoch 401/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4564 - accuracy: 0.8050 - val_loss: 0.4566 - val_accuracy: 0.8044\n",
      "Epoch 402/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7935 - val_loss: 0.4583 - val_accuracy: 0.8089\n",
      "Epoch 403/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7935 - val_loss: 0.4586 - val_accuracy: 0.8089\n",
      "Epoch 404/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7992 - val_loss: 0.4576 - val_accuracy: 0.8133\n",
      "Epoch 405/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.8031 - val_loss: 0.4591 - val_accuracy: 0.8089\n",
      "Epoch 406/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.8050 - val_loss: 0.4581 - val_accuracy: 0.8089\n",
      "Epoch 407/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7878 - val_loss: 0.4596 - val_accuracy: 0.8089\n",
      "Epoch 408/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7973 - val_loss: 0.4576 - val_accuracy: 0.8089\n",
      "Epoch 409/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4569 - accuracy: 0.7992 - val_loss: 0.4566 - val_accuracy: 0.8089\n",
      "Epoch 410/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.7992 - val_loss: 0.4592 - val_accuracy: 0.8089\n",
      "Epoch 411/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.8088 - val_loss: 0.4577 - val_accuracy: 0.8133\n",
      "Epoch 412/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.7954 - val_loss: 0.4564 - val_accuracy: 0.8089\n",
      "Epoch 413/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7954 - val_loss: 0.4576 - val_accuracy: 0.8089\n",
      "Epoch 414/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7992 - val_loss: 0.4556 - val_accuracy: 0.8178\n",
      "Epoch 415/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7859 - val_loss: 0.4593 - val_accuracy: 0.8089\n",
      "Epoch 416/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7973 - val_loss: 0.4566 - val_accuracy: 0.8178\n",
      "Epoch 417/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.8031 - val_loss: 0.4575 - val_accuracy: 0.8089\n",
      "Epoch 418/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7935 - val_loss: 0.4560 - val_accuracy: 0.8089\n",
      "Epoch 419/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4569 - accuracy: 0.7859 - val_loss: 0.4575 - val_accuracy: 0.8133\n",
      "Epoch 420/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4587 - accuracy: 0.7973 - val_loss: 0.4601 - val_accuracy: 0.8044\n",
      "Epoch 421/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7973 - val_loss: 0.4556 - val_accuracy: 0.8089\n",
      "Epoch 422/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4556 - accuracy: 0.7973 - val_loss: 0.4546 - val_accuracy: 0.8089\n",
      "Epoch 423/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4548 - accuracy: 0.7973 - val_loss: 0.4575 - val_accuracy: 0.8089\n",
      "Epoch 424/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4551 - accuracy: 0.7973 - val_loss: 0.4572 - val_accuracy: 0.8089\n",
      "Epoch 425/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4558 - accuracy: 0.7973 - val_loss: 0.4557 - val_accuracy: 0.8178\n",
      "Epoch 426/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4568 - accuracy: 0.8069 - val_loss: 0.4575 - val_accuracy: 0.8089\n",
      "Epoch 427/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4570 - accuracy: 0.8011 - val_loss: 0.4578 - val_accuracy: 0.8089\n",
      "Epoch 428/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4550 - accuracy: 0.7973 - val_loss: 0.4586 - val_accuracy: 0.8089\n",
      "Epoch 429/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4520 - accuracy: 0.8031 - val_loss: 0.4551 - val_accuracy: 0.8044\n",
      "Epoch 430/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.7973 - val_loss: 0.4557 - val_accuracy: 0.8178\n",
      "Epoch 431/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.7992 - val_loss: 0.4577 - val_accuracy: 0.8089\n",
      "Epoch 432/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.7878 - val_loss: 0.4611 - val_accuracy: 0.8089\n",
      "Epoch 433/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4588 - accuracy: 0.8011 - val_loss: 0.4557 - val_accuracy: 0.8222\n",
      "Epoch 434/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7859 - val_loss: 0.4578 - val_accuracy: 0.8089\n",
      "Epoch 435/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7992 - val_loss: 0.4563 - val_accuracy: 0.8089\n",
      "Epoch 436/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7839 - val_loss: 0.4554 - val_accuracy: 0.8133\n",
      "Epoch 437/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7973 - val_loss: 0.4578 - val_accuracy: 0.8089\n",
      "Epoch 438/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.8050 - val_loss: 0.4607 - val_accuracy: 0.8089\n",
      "Epoch 439/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.8011 - val_loss: 0.4564 - val_accuracy: 0.8089\n",
      "Epoch 440/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7935 - val_loss: 0.4578 - val_accuracy: 0.8089\n",
      "Epoch 441/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.8088 - val_loss: 0.4573 - val_accuracy: 0.8089\n",
      "Epoch 442/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.8050 - val_loss: 0.4557 - val_accuracy: 0.8089\n",
      "Epoch 443/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4519 - accuracy: 0.7897 - val_loss: 0.4557 - val_accuracy: 0.8089\n",
      "Epoch 444/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4526 - accuracy: 0.8011 - val_loss: 0.4576 - val_accuracy: 0.8089\n",
      "Epoch 445/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.8011 - val_loss: 0.4574 - val_accuracy: 0.8089\n",
      "Epoch 446/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.8031 - val_loss: 0.4579 - val_accuracy: 0.8089\n",
      "Epoch 447/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.8050 - val_loss: 0.4581 - val_accuracy: 0.8089\n",
      "Epoch 448/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.8050 - val_loss: 0.4570 - val_accuracy: 0.8089\n",
      "Epoch 449/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7954 - val_loss: 0.4575 - val_accuracy: 0.8089\n",
      "Epoch 450/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4540 - accuracy: 0.8050 - val_loss: 0.4571 - val_accuracy: 0.8133\n",
      "Epoch 451/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4570 - accuracy: 0.8011 - val_loss: 0.4568 - val_accuracy: 0.8089\n",
      "Epoch 452/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7973 - val_loss: 0.4574 - val_accuracy: 0.8089\n",
      "Epoch 453/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4536 - accuracy: 0.7973 - val_loss: 0.4582 - val_accuracy: 0.8089\n",
      "Epoch 454/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4541 - accuracy: 0.7992 - val_loss: 0.4564 - val_accuracy: 0.8178\n",
      "Epoch 455/1600\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.4539 - accuracy: 0.8031 - val_loss: 0.4566 - val_accuracy: 0.8133\n",
      "Epoch 456/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4565 - accuracy: 0.7897 - val_loss: 0.4572 - val_accuracy: 0.8089\n",
      "Epoch 457/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4523 - accuracy: 0.7954 - val_loss: 0.4608 - val_accuracy: 0.8089\n",
      "Epoch 458/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4553 - accuracy: 0.8011 - val_loss: 0.4573 - val_accuracy: 0.8089\n",
      "Epoch 459/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4546 - accuracy: 0.8011 - val_loss: 0.4585 - val_accuracy: 0.8089\n",
      "Epoch 460/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4530 - accuracy: 0.7859 - val_loss: 0.4560 - val_accuracy: 0.8089\n",
      "Epoch 461/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7992 - val_loss: 0.4570 - val_accuracy: 0.8133\n",
      "Epoch 462/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4508 - accuracy: 0.7916 - val_loss: 0.4588 - val_accuracy: 0.8089\n",
      "Epoch 463/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.8050 - val_loss: 0.4587 - val_accuracy: 0.8089\n",
      "Epoch 464/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.8011 - val_loss: 0.4590 - val_accuracy: 0.8044\n",
      "Epoch 465/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.7935 - val_loss: 0.4582 - val_accuracy: 0.8089\n",
      "Epoch 466/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7973 - val_loss: 0.4617 - val_accuracy: 0.8044\n",
      "Epoch 467/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7954 - val_loss: 0.4577 - val_accuracy: 0.8000\n",
      "Epoch 468/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.8050 - val_loss: 0.4575 - val_accuracy: 0.8089\n",
      "Epoch 469/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7954 - val_loss: 0.4587 - val_accuracy: 0.8089\n",
      "Epoch 470/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4553 - accuracy: 0.8011 - val_loss: 0.4572 - val_accuracy: 0.8089\n",
      "Epoch 471/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4526 - accuracy: 0.7973 - val_loss: 0.4584 - val_accuracy: 0.8089\n",
      "Epoch 472/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.8050 - val_loss: 0.4564 - val_accuracy: 0.8044\n",
      "Epoch 473/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4500 - accuracy: 0.8069 - val_loss: 0.4572 - val_accuracy: 0.8044\n",
      "Epoch 474/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4608 - accuracy: 0.7954 - val_loss: 0.4563 - val_accuracy: 0.8000\n",
      "Epoch 475/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4546 - accuracy: 0.7916 - val_loss: 0.4583 - val_accuracy: 0.8089\n",
      "Epoch 476/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4503 - accuracy: 0.7897 - val_loss: 0.4584 - val_accuracy: 0.8089\n",
      "Epoch 477/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.8031 - val_loss: 0.4574 - val_accuracy: 0.8000\n",
      "Epoch 478/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7954 - val_loss: 0.4579 - val_accuracy: 0.8044\n",
      "Epoch 479/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7935 - val_loss: 0.4596 - val_accuracy: 0.8044\n",
      "Epoch 480/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7954 - val_loss: 0.4587 - val_accuracy: 0.8089\n",
      "Epoch 481/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.7954 - val_loss: 0.4568 - val_accuracy: 0.8089\n",
      "Epoch 482/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.8011 - val_loss: 0.4586 - val_accuracy: 0.8089\n",
      "Epoch 483/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.8011 - val_loss: 0.4565 - val_accuracy: 0.8089\n",
      "Epoch 484/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7992 - val_loss: 0.4579 - val_accuracy: 0.8089\n",
      "Epoch 485/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.8088 - val_loss: 0.4564 - val_accuracy: 0.8044\n",
      "Epoch 486/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4574 - accuracy: 0.7973 - val_loss: 0.4605 - val_accuracy: 0.8089\n",
      "Epoch 487/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4609 - accuracy: 0.7897 - val_loss: 0.4575 - val_accuracy: 0.8000\n",
      "Epoch 488/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4507 - accuracy: 0.8011 - val_loss: 0.4566 - val_accuracy: 0.8089\n",
      "Epoch 489/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4517 - accuracy: 0.8031 - val_loss: 0.4558 - val_accuracy: 0.8089\n",
      "Epoch 490/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4530 - accuracy: 0.8031 - val_loss: 0.4569 - val_accuracy: 0.8089\n",
      "Epoch 491/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4537 - accuracy: 0.7935 - val_loss: 0.4592 - val_accuracy: 0.8089\n",
      "Epoch 492/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.8088 - val_loss: 0.4563 - val_accuracy: 0.8089\n",
      "Epoch 493/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4506 - accuracy: 0.7935 - val_loss: 0.4573 - val_accuracy: 0.8089\n",
      "Epoch 494/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4463 - accuracy: 0.8088 - val_loss: 0.4565 - val_accuracy: 0.8089\n",
      "Epoch 495/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7954 - val_loss: 0.4557 - val_accuracy: 0.8000\n",
      "Epoch 496/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7859 - val_loss: 0.4589 - val_accuracy: 0.8044\n",
      "Epoch 497/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7897 - val_loss: 0.4557 - val_accuracy: 0.8089\n",
      "Epoch 498/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.8088 - val_loss: 0.4597 - val_accuracy: 0.8089\n",
      "Epoch 499/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7954 - val_loss: 0.4578 - val_accuracy: 0.8089\n",
      "Epoch 500/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.8069 - val_loss: 0.4586 - val_accuracy: 0.8089\n",
      "Epoch 501/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.7954 - val_loss: 0.4555 - val_accuracy: 0.8222\n",
      "Epoch 502/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.8011 - val_loss: 0.4570 - val_accuracy: 0.8133\n",
      "Epoch 503/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7954 - val_loss: 0.4577 - val_accuracy: 0.8089\n",
      "Epoch 504/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7954 - val_loss: 0.4563 - val_accuracy: 0.8089\n",
      "Epoch 505/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.8050 - val_loss: 0.4574 - val_accuracy: 0.8089\n",
      "Epoch 506/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7916 - val_loss: 0.4571 - val_accuracy: 0.8089\n",
      "Epoch 507/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.8050 - val_loss: 0.4567 - val_accuracy: 0.8133\n",
      "Epoch 508/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4503 - accuracy: 0.8031 - val_loss: 0.4560 - val_accuracy: 0.8089\n",
      "Epoch 509/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4494 - accuracy: 0.8011 - val_loss: 0.4559 - val_accuracy: 0.8089\n",
      "Epoch 510/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4519 - accuracy: 0.8011 - val_loss: 0.4575 - val_accuracy: 0.8089\n",
      "Epoch 511/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4501 - accuracy: 0.8011 - val_loss: 0.4565 - val_accuracy: 0.8133\n",
      "Epoch 512/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.8069 - val_loss: 0.4573 - val_accuracy: 0.8089\n",
      "Epoch 513/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.8011 - val_loss: 0.4566 - val_accuracy: 0.8089\n",
      "Epoch 514/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7935 - val_loss: 0.4562 - val_accuracy: 0.8044\n",
      "Epoch 515/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7992 - val_loss: 0.4575 - val_accuracy: 0.8044\n",
      "Epoch 516/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4516 - accuracy: 0.7992 - val_loss: 0.4572 - val_accuracy: 0.8044\n",
      "Epoch 517/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4478 - accuracy: 0.7954 - val_loss: 0.4575 - val_accuracy: 0.8044\n",
      "Epoch 518/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7973 - val_loss: 0.4580 - val_accuracy: 0.8089\n",
      "Epoch 519/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4531 - accuracy: 0.7992 - val_loss: 0.4598 - val_accuracy: 0.8089\n",
      "Epoch 520/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4516 - accuracy: 0.8011 - val_loss: 0.4563 - val_accuracy: 0.8044\n",
      "Epoch 521/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.8088 - val_loss: 0.4563 - val_accuracy: 0.8089\n",
      "Epoch 522/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4520 - accuracy: 0.7973 - val_loss: 0.4564 - val_accuracy: 0.8133\n",
      "Epoch 523/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4548 - accuracy: 0.8145 - val_loss: 0.4574 - val_accuracy: 0.8089\n",
      "Epoch 524/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4470 - accuracy: 0.7992 - val_loss: 0.4609 - val_accuracy: 0.8089\n",
      "Epoch 525/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.7954 - val_loss: 0.4564 - val_accuracy: 0.8133\n",
      "Epoch 526/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4534 - accuracy: 0.7992 - val_loss: 0.4551 - val_accuracy: 0.8178\n",
      "Epoch 527/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4516 - accuracy: 0.8050 - val_loss: 0.4573 - val_accuracy: 0.8089\n",
      "Epoch 528/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7992 - val_loss: 0.4562 - val_accuracy: 0.8133\n",
      "Epoch 529/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4456 - accuracy: 0.8031 - val_loss: 0.4569 - val_accuracy: 0.8089\n",
      "Epoch 530/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.8069 - val_loss: 0.4544 - val_accuracy: 0.8178\n",
      "Epoch 531/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7878 - val_loss: 0.4575 - val_accuracy: 0.8089\n",
      "Epoch 532/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7992 - val_loss: 0.4569 - val_accuracy: 0.8089\n",
      "Epoch 533/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7954 - val_loss: 0.4594 - val_accuracy: 0.8089\n",
      "Epoch 534/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.8050 - val_loss: 0.4577 - val_accuracy: 0.8133\n",
      "Epoch 535/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7916 - val_loss: 0.4591 - val_accuracy: 0.8089\n",
      "Epoch 536/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4547 - accuracy: 0.7916 - val_loss: 0.4573 - val_accuracy: 0.8089\n",
      "Epoch 537/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4499 - accuracy: 0.8031 - val_loss: 0.4580 - val_accuracy: 0.8089\n",
      "Epoch 538/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4512 - accuracy: 0.7992 - val_loss: 0.4568 - val_accuracy: 0.8089\n",
      "Epoch 539/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7954 - val_loss: 0.4569 - val_accuracy: 0.8089\n",
      "Epoch 540/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7878 - val_loss: 0.4586 - val_accuracy: 0.8089\n",
      "Epoch 541/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.8050 - val_loss: 0.4561 - val_accuracy: 0.8178\n",
      "Epoch 542/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7954 - val_loss: 0.4580 - val_accuracy: 0.8089\n",
      "Epoch 543/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.8011 - val_loss: 0.4584 - val_accuracy: 0.8089\n",
      "Epoch 544/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4522 - accuracy: 0.7973 - val_loss: 0.4585 - val_accuracy: 0.8089\n",
      "Epoch 545/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4540 - accuracy: 0.7839 - val_loss: 0.4604 - val_accuracy: 0.8089\n",
      "Epoch 546/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4555 - accuracy: 0.7992 - val_loss: 0.4585 - val_accuracy: 0.8089\n",
      "Epoch 547/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4506 - accuracy: 0.7973 - val_loss: 0.4579 - val_accuracy: 0.8089\n",
      "Epoch 548/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4532 - accuracy: 0.7916 - val_loss: 0.4579 - val_accuracy: 0.8089\n",
      "Epoch 549/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7992 - val_loss: 0.4565 - val_accuracy: 0.8089\n",
      "Epoch 550/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7973 - val_loss: 0.4578 - val_accuracy: 0.8133\n",
      "Epoch 551/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4551 - accuracy: 0.8031 - val_loss: 0.4578 - val_accuracy: 0.8089\n",
      "Epoch 552/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4563 - accuracy: 0.7992 - val_loss: 0.4598 - val_accuracy: 0.8089\n",
      "Epoch 553/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7973 - val_loss: 0.4588 - val_accuracy: 0.8089\n",
      "Epoch 554/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4487 - accuracy: 0.8050 - val_loss: 0.4575 - val_accuracy: 0.8089\n",
      "Epoch 555/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.8069 - val_loss: 0.4599 - val_accuracy: 0.8089\n",
      "Epoch 556/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4547 - accuracy: 0.8069 - val_loss: 0.4563 - val_accuracy: 0.8133\n",
      "Epoch 557/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7935 - val_loss: 0.4590 - val_accuracy: 0.8089\n",
      "Epoch 558/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.7992 - val_loss: 0.4570 - val_accuracy: 0.8089\n",
      "Epoch 559/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.7973 - val_loss: 0.4586 - val_accuracy: 0.8089\n",
      "Epoch 560/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4543 - accuracy: 0.8031 - val_loss: 0.4601 - val_accuracy: 0.8089\n",
      "Epoch 561/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4541 - accuracy: 0.8011 - val_loss: 0.4569 - val_accuracy: 0.8133\n",
      "Epoch 562/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.8050 - val_loss: 0.4574 - val_accuracy: 0.8089\n",
      "Epoch 563/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4552 - accuracy: 0.7916 - val_loss: 0.4591 - val_accuracy: 0.8089\n",
      "Epoch 564/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4468 - accuracy: 0.8050 - val_loss: 0.4581 - val_accuracy: 0.8089\n",
      "Epoch 565/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4557 - accuracy: 0.7897 - val_loss: 0.4569 - val_accuracy: 0.8089\n",
      "Epoch 566/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.7878 - val_loss: 0.4576 - val_accuracy: 0.8000\n",
      "Epoch 567/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7992 - val_loss: 0.4575 - val_accuracy: 0.8000\n",
      "Epoch 568/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.8050 - val_loss: 0.4589 - val_accuracy: 0.8089\n",
      "Epoch 569/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4537 - accuracy: 0.8011 - val_loss: 0.4571 - val_accuracy: 0.8089\n",
      "Epoch 570/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7954 - val_loss: 0.4573 - val_accuracy: 0.8089\n",
      "Epoch 571/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7973 - val_loss: 0.4574 - val_accuracy: 0.8089\n",
      "Epoch 572/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4531 - accuracy: 0.7935 - val_loss: 0.4574 - val_accuracy: 0.8000\n",
      "Epoch 573/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4521 - accuracy: 0.7878 - val_loss: 0.4582 - val_accuracy: 0.8089\n",
      "Epoch 574/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.8011 - val_loss: 0.4556 - val_accuracy: 0.8133\n",
      "Epoch 575/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.8031 - val_loss: 0.4580 - val_accuracy: 0.8089\n",
      "Epoch 576/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4519 - accuracy: 0.7992 - val_loss: 0.4559 - val_accuracy: 0.8178\n",
      "Epoch 577/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4455 - accuracy: 0.7992 - val_loss: 0.4581 - val_accuracy: 0.8089\n",
      "Epoch 578/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.8011 - val_loss: 0.4571 - val_accuracy: 0.8178\n",
      "Epoch 579/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4466 - accuracy: 0.7954 - val_loss: 0.4572 - val_accuracy: 0.8089\n",
      "Epoch 580/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7954 - val_loss: 0.4561 - val_accuracy: 0.8089\n",
      "Epoch 581/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.7954 - val_loss: 0.4569 - val_accuracy: 0.8044\n",
      "Epoch 582/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4512 - accuracy: 0.7878 - val_loss: 0.4585 - val_accuracy: 0.8089\n",
      "Epoch 583/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4480 - accuracy: 0.8031 - val_loss: 0.4556 - val_accuracy: 0.8089\n",
      "Epoch 584/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.8011 - val_loss: 0.4556 - val_accuracy: 0.8089\n",
      "Epoch 585/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4520 - accuracy: 0.8011 - val_loss: 0.4558 - val_accuracy: 0.8133\n",
      "Epoch 586/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7973 - val_loss: 0.4548 - val_accuracy: 0.8133\n",
      "Epoch 587/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4517 - accuracy: 0.7935 - val_loss: 0.4571 - val_accuracy: 0.8044\n",
      "Epoch 588/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.7992 - val_loss: 0.4566 - val_accuracy: 0.8089\n",
      "Epoch 589/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7992 - val_loss: 0.4558 - val_accuracy: 0.8133\n",
      "Epoch 590/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7954 - val_loss: 0.4570 - val_accuracy: 0.8089\n",
      "Epoch 591/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7935 - val_loss: 0.4561 - val_accuracy: 0.8089\n",
      "Epoch 592/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.8031 - val_loss: 0.4567 - val_accuracy: 0.8044\n",
      "Epoch 593/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4533 - accuracy: 0.7992 - val_loss: 0.4571 - val_accuracy: 0.8089\n",
      "Epoch 594/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7935 - val_loss: 0.4581 - val_accuracy: 0.8089\n",
      "Epoch 595/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.7935 - val_loss: 0.4555 - val_accuracy: 0.8133\n",
      "Epoch 596/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7992 - val_loss: 0.4573 - val_accuracy: 0.8133\n",
      "Epoch 597/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7916 - val_loss: 0.4568 - val_accuracy: 0.8133\n",
      "Epoch 598/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.8011 - val_loss: 0.4565 - val_accuracy: 0.8133\n",
      "Epoch 599/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7916 - val_loss: 0.4571 - val_accuracy: 0.8089\n",
      "Epoch 600/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7954 - val_loss: 0.4572 - val_accuracy: 0.8089\n",
      "Epoch 601/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.8011 - val_loss: 0.4583 - val_accuracy: 0.8089\n",
      "Epoch 602/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7916 - val_loss: 0.4568 - val_accuracy: 0.8133\n",
      "Epoch 603/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.8088 - val_loss: 0.4583 - val_accuracy: 0.8089\n",
      "Epoch 604/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7973 - val_loss: 0.4567 - val_accuracy: 0.8089\n",
      "Epoch 605/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.8031 - val_loss: 0.4572 - val_accuracy: 0.8178\n",
      "Epoch 606/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.8050 - val_loss: 0.4577 - val_accuracy: 0.8089\n",
      "Epoch 607/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.8069 - val_loss: 0.4552 - val_accuracy: 0.8133\n",
      "Epoch 608/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7859 - val_loss: 0.4561 - val_accuracy: 0.8133\n",
      "Epoch 609/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7973 - val_loss: 0.4557 - val_accuracy: 0.8178\n",
      "Epoch 610/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.8011 - val_loss: 0.4574 - val_accuracy: 0.8089\n",
      "Epoch 611/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.8011 - val_loss: 0.4566 - val_accuracy: 0.8178\n",
      "Epoch 612/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7992 - val_loss: 0.4556 - val_accuracy: 0.8222\n",
      "Epoch 613/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.8050 - val_loss: 0.4568 - val_accuracy: 0.8133\n",
      "Epoch 614/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.8011 - val_loss: 0.4579 - val_accuracy: 0.8089\n",
      "Epoch 615/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.8050 - val_loss: 0.4568 - val_accuracy: 0.8133\n",
      "Epoch 616/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.7973 - val_loss: 0.4559 - val_accuracy: 0.8133\n",
      "Epoch 617/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.8031 - val_loss: 0.4579 - val_accuracy: 0.8089\n",
      "Epoch 618/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.8050 - val_loss: 0.4558 - val_accuracy: 0.8089\n",
      "Epoch 619/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7954 - val_loss: 0.4565 - val_accuracy: 0.8178\n",
      "Epoch 620/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7916 - val_loss: 0.4561 - val_accuracy: 0.8133\n",
      "Epoch 621/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7935 - val_loss: 0.4557 - val_accuracy: 0.8178\n",
      "Epoch 622/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7992 - val_loss: 0.4570 - val_accuracy: 0.8089\n",
      "Epoch 623/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.8050 - val_loss: 0.4557 - val_accuracy: 0.8089\n",
      "Epoch 624/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.8011 - val_loss: 0.4584 - val_accuracy: 0.8089\n",
      "Epoch 625/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7954 - val_loss: 0.4562 - val_accuracy: 0.8044\n",
      "Epoch 626/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7954 - val_loss: 0.4582 - val_accuracy: 0.8089\n",
      "Epoch 627/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7954 - val_loss: 0.4607 - val_accuracy: 0.8044\n",
      "Epoch 628/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.8011 - val_loss: 0.4567 - val_accuracy: 0.8133\n",
      "Epoch 629/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.8069 - val_loss: 0.4569 - val_accuracy: 0.8089\n",
      "Epoch 630/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.8011 - val_loss: 0.4545 - val_accuracy: 0.8178\n",
      "Epoch 631/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7992 - val_loss: 0.4558 - val_accuracy: 0.8089\n",
      "Epoch 632/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.8050 - val_loss: 0.4566 - val_accuracy: 0.8133\n",
      "Epoch 633/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4476 - accuracy: 0.7992 - val_loss: 0.4582 - val_accuracy: 0.8044\n",
      "Epoch 634/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4524 - accuracy: 0.7916 - val_loss: 0.4569 - val_accuracy: 0.8089\n",
      "Epoch 635/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.8069 - val_loss: 0.4581 - val_accuracy: 0.8044\n",
      "Epoch 636/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.8011 - val_loss: 0.4564 - val_accuracy: 0.8089\n",
      "Epoch 637/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4497 - accuracy: 0.8011 - val_loss: 0.4569 - val_accuracy: 0.8044\n",
      "Epoch 638/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.8011 - val_loss: 0.4571 - val_accuracy: 0.8089\n",
      "Epoch 639/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4473 - accuracy: 0.8107 - val_loss: 0.4582 - val_accuracy: 0.8089\n",
      "Epoch 640/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.7954 - val_loss: 0.4569 - val_accuracy: 0.8089\n",
      "Epoch 641/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.8050 - val_loss: 0.4587 - val_accuracy: 0.8044\n",
      "Epoch 642/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.8011 - val_loss: 0.4582 - val_accuracy: 0.8089\n",
      "Epoch 643/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4503 - accuracy: 0.7973 - val_loss: 0.4574 - val_accuracy: 0.8089\n",
      "Epoch 644/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4490 - accuracy: 0.8050 - val_loss: 0.4573 - val_accuracy: 0.8044\n",
      "Epoch 645/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4505 - accuracy: 0.8011 - val_loss: 0.4576 - val_accuracy: 0.8089\n",
      "Epoch 646/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.8031 - val_loss: 0.4560 - val_accuracy: 0.8089\n",
      "Epoch 647/1600\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.4472 - accuracy: 0.8011 - val_loss: 0.4572 - val_accuracy: 0.8044\n",
      "Epoch 648/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4505 - accuracy: 0.7992 - val_loss: 0.4567 - val_accuracy: 0.8089\n",
      "Epoch 649/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4486 - accuracy: 0.7935 - val_loss: 0.4567 - val_accuracy: 0.8089\n",
      "Epoch 650/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4510 - accuracy: 0.7973 - val_loss: 0.4560 - val_accuracy: 0.8089\n",
      "Epoch 651/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4536 - accuracy: 0.7935 - val_loss: 0.4567 - val_accuracy: 0.8133\n",
      "Epoch 652/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7916 - val_loss: 0.4578 - val_accuracy: 0.8133\n",
      "Epoch 653/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4465 - accuracy: 0.8050 - val_loss: 0.4573 - val_accuracy: 0.8044\n",
      "Epoch 654/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4479 - accuracy: 0.8011 - val_loss: 0.4554 - val_accuracy: 0.8089\n",
      "Epoch 655/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4505 - accuracy: 0.7954 - val_loss: 0.4575 - val_accuracy: 0.8044\n",
      "Epoch 656/1600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4513 - accuracy: 0.8011 - val_loss: 0.4578 - val_accuracy: 0.8044\n",
      "Epoch 657/1600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4530 - accuracy: 0.8011 - val_loss: 0.4566 - val_accuracy: 0.8044\n",
      "Epoch 658/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4541 - accuracy: 0.8011 - val_loss: 0.4566 - val_accuracy: 0.8044\n",
      "Epoch 659/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4525 - accuracy: 0.8031 - val_loss: 0.4563 - val_accuracy: 0.8089\n",
      "Epoch 660/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4534 - accuracy: 0.7954 - val_loss: 0.4588 - val_accuracy: 0.8044\n",
      "Epoch 661/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4485 - accuracy: 0.7954 - val_loss: 0.4551 - val_accuracy: 0.8044\n",
      "Epoch 662/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4484 - accuracy: 0.7954 - val_loss: 0.4554 - val_accuracy: 0.8089\n",
      "Epoch 663/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4504 - accuracy: 0.8011 - val_loss: 0.4560 - val_accuracy: 0.8178\n",
      "Epoch 664/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4466 - accuracy: 0.8088 - val_loss: 0.4559 - val_accuracy: 0.8089\n",
      "Epoch 665/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4547 - accuracy: 0.8031 - val_loss: 0.4547 - val_accuracy: 0.8089\n",
      "Epoch 666/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4512 - accuracy: 0.7878 - val_loss: 0.4572 - val_accuracy: 0.8178\n",
      "Epoch 667/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4541 - accuracy: 0.7916 - val_loss: 0.4555 - val_accuracy: 0.8133\n",
      "Epoch 668/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4501 - accuracy: 0.8011 - val_loss: 0.4572 - val_accuracy: 0.8089\n",
      "Epoch 669/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4502 - accuracy: 0.7897 - val_loss: 0.4579 - val_accuracy: 0.8044\n",
      "Epoch 670/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.7801 - val_loss: 0.4561 - val_accuracy: 0.8133\n",
      "Epoch 671/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.8031 - val_loss: 0.4576 - val_accuracy: 0.8133\n",
      "Epoch 672/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4515 - accuracy: 0.7992 - val_loss: 0.4568 - val_accuracy: 0.8133\n",
      "Epoch 673/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.8088 - val_loss: 0.4581 - val_accuracy: 0.8044\n",
      "Epoch 674/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7992 - val_loss: 0.4574 - val_accuracy: 0.8178\n",
      "Epoch 675/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4540 - accuracy: 0.7992 - val_loss: 0.4559 - val_accuracy: 0.8133\n",
      "Epoch 676/1600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4480 - accuracy: 0.8031 - val_loss: 0.4577 - val_accuracy: 0.8089\n",
      "Epoch 677/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4461 - accuracy: 0.7992 - val_loss: 0.4572 - val_accuracy: 0.8044\n",
      "Epoch 678/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4526 - accuracy: 0.8031 - val_loss: 0.4564 - val_accuracy: 0.8089\n",
      "Epoch 679/1600\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.4554 - accuracy: 0.7973 - val_loss: 0.4595 - val_accuracy: 0.8044\n",
      "Epoch 680/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4483 - accuracy: 0.8031 - val_loss: 0.4573 - val_accuracy: 0.8044\n",
      "Epoch 681/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4468 - accuracy: 0.8011 - val_loss: 0.4560 - val_accuracy: 0.8044\n",
      "Epoch 682/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4491 - accuracy: 0.7973 - val_loss: 0.4536 - val_accuracy: 0.8133\n",
      "Epoch 683/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4525 - accuracy: 0.8011 - val_loss: 0.4585 - val_accuracy: 0.8044\n",
      "Epoch 684/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4514 - accuracy: 0.8011 - val_loss: 0.4576 - val_accuracy: 0.8089\n",
      "Epoch 685/1600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4516 - accuracy: 0.7954 - val_loss: 0.4549 - val_accuracy: 0.8133\n",
      "Epoch 686/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4521 - accuracy: 0.7954 - val_loss: 0.4562 - val_accuracy: 0.8044\n",
      "Epoch 687/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4479 - accuracy: 0.8011 - val_loss: 0.4581 - val_accuracy: 0.8133\n",
      "Epoch 688/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4469 - accuracy: 0.8050 - val_loss: 0.4550 - val_accuracy: 0.8133\n",
      "Epoch 689/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4464 - accuracy: 0.7973 - val_loss: 0.4586 - val_accuracy: 0.8133\n",
      "Epoch 690/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4438 - accuracy: 0.7992 - val_loss: 0.4563 - val_accuracy: 0.8089\n",
      "Epoch 691/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4519 - accuracy: 0.8050 - val_loss: 0.4565 - val_accuracy: 0.8089\n",
      "Epoch 692/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4511 - accuracy: 0.8011 - val_loss: 0.4554 - val_accuracy: 0.8044\n",
      "Epoch 693/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.7973 - val_loss: 0.4560 - val_accuracy: 0.8089\n",
      "Epoch 694/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4465 - accuracy: 0.8069 - val_loss: 0.4565 - val_accuracy: 0.8089\n",
      "Epoch 695/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4508 - accuracy: 0.7954 - val_loss: 0.4594 - val_accuracy: 0.8044\n",
      "Epoch 696/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4501 - accuracy: 0.8031 - val_loss: 0.4571 - val_accuracy: 0.8089\n",
      "Epoch 697/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4517 - accuracy: 0.8031 - val_loss: 0.4579 - val_accuracy: 0.8089\n",
      "Epoch 698/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4498 - accuracy: 0.8011 - val_loss: 0.4577 - val_accuracy: 0.8089\n",
      "Epoch 699/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4494 - accuracy: 0.8031 - val_loss: 0.4590 - val_accuracy: 0.8000\n",
      "Epoch 700/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4518 - accuracy: 0.7973 - val_loss: 0.4585 - val_accuracy: 0.8000\n",
      "Epoch 701/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4539 - accuracy: 0.8031 - val_loss: 0.4583 - val_accuracy: 0.8089\n",
      "Epoch 702/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4523 - accuracy: 0.7992 - val_loss: 0.4580 - val_accuracy: 0.8044\n",
      "Epoch 703/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4463 - accuracy: 0.7973 - val_loss: 0.4574 - val_accuracy: 0.8044\n",
      "Epoch 704/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4528 - accuracy: 0.8011 - val_loss: 0.4569 - val_accuracy: 0.8089\n",
      "Epoch 705/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4434 - accuracy: 0.8031 - val_loss: 0.4571 - val_accuracy: 0.8044\n",
      "Epoch 706/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4470 - accuracy: 0.7935 - val_loss: 0.4561 - val_accuracy: 0.8089\n",
      "Epoch 707/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4510 - accuracy: 0.8050 - val_loss: 0.4550 - val_accuracy: 0.8089\n",
      "Epoch 708/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4475 - accuracy: 0.7973 - val_loss: 0.4543 - val_accuracy: 0.8133\n",
      "Epoch 709/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4547 - accuracy: 0.7992 - val_loss: 0.4572 - val_accuracy: 0.8133\n",
      "Epoch 710/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4451 - accuracy: 0.8107 - val_loss: 0.4573 - val_accuracy: 0.8133\n",
      "Epoch 711/1600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4510 - accuracy: 0.7973 - val_loss: 0.4573 - val_accuracy: 0.8044\n",
      "Epoch 712/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4570 - accuracy: 0.8011 - val_loss: 0.4577 - val_accuracy: 0.8044\n",
      "Epoch 713/1600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4472 - accuracy: 0.8069 - val_loss: 0.4594 - val_accuracy: 0.8089\n",
      "Epoch 714/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4464 - accuracy: 0.8088 - val_loss: 0.4585 - val_accuracy: 0.8089\n",
      "Epoch 715/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4480 - accuracy: 0.7992 - val_loss: 0.4594 - val_accuracy: 0.8044\n",
      "Epoch 716/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4479 - accuracy: 0.8011 - val_loss: 0.4578 - val_accuracy: 0.8133\n",
      "Epoch 717/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.8031 - val_loss: 0.4580 - val_accuracy: 0.8089\n",
      "Epoch 718/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7954 - val_loss: 0.4569 - val_accuracy: 0.8133\n",
      "Epoch 719/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4514 - accuracy: 0.8050 - val_loss: 0.4573 - val_accuracy: 0.8089\n",
      "Epoch 720/1600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4478 - accuracy: 0.7973 - val_loss: 0.4582 - val_accuracy: 0.8044\n",
      "Epoch 721/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4519 - accuracy: 0.7973 - val_loss: 0.4597 - val_accuracy: 0.8089\n",
      "Epoch 722/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4477 - accuracy: 0.7954 - val_loss: 0.4620 - val_accuracy: 0.7956\n",
      "Epoch 723/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4496 - accuracy: 0.7916 - val_loss: 0.4584 - val_accuracy: 0.8133\n",
      "Epoch 724/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4456 - accuracy: 0.7992 - val_loss: 0.4577 - val_accuracy: 0.8133\n",
      "Epoch 725/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4487 - accuracy: 0.8011 - val_loss: 0.4570 - val_accuracy: 0.8089\n",
      "Epoch 726/1600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.4558 - accuracy: 0.8011 - val_loss: 0.4562 - val_accuracy: 0.8044\n",
      "Epoch 727/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4484 - accuracy: 0.8011 - val_loss: 0.4589 - val_accuracy: 0.8000\n",
      "Epoch 728/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4513 - accuracy: 0.7820 - val_loss: 0.4595 - val_accuracy: 0.8000\n",
      "Epoch 729/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4460 - accuracy: 0.7992 - val_loss: 0.4580 - val_accuracy: 0.8089\n",
      "Epoch 730/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4466 - accuracy: 0.8011 - val_loss: 0.4570 - val_accuracy: 0.8089\n",
      "Epoch 731/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4450 - accuracy: 0.8050 - val_loss: 0.4568 - val_accuracy: 0.8089\n",
      "Epoch 732/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4444 - accuracy: 0.8050 - val_loss: 0.4597 - val_accuracy: 0.8089\n",
      "Epoch 733/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4482 - accuracy: 0.8088 - val_loss: 0.4577 - val_accuracy: 0.8089\n",
      "Epoch 734/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4497 - accuracy: 0.7992 - val_loss: 0.4586 - val_accuracy: 0.8089\n",
      "Epoch 735/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4509 - accuracy: 0.7973 - val_loss: 0.4583 - val_accuracy: 0.8044\n",
      "Epoch 736/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4479 - accuracy: 0.8069 - val_loss: 0.4592 - val_accuracy: 0.8089\n",
      "Epoch 737/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4476 - accuracy: 0.7992 - val_loss: 0.4593 - val_accuracy: 0.8044\n",
      "Epoch 738/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4425 - accuracy: 0.8011 - val_loss: 0.4587 - val_accuracy: 0.8089\n",
      "Epoch 739/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4426 - accuracy: 0.8031 - val_loss: 0.4586 - val_accuracy: 0.8133\n",
      "Epoch 740/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.7916 - val_loss: 0.4581 - val_accuracy: 0.8133\n",
      "Epoch 741/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7973 - val_loss: 0.4593 - val_accuracy: 0.8133\n",
      "Epoch 742/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7954 - val_loss: 0.4595 - val_accuracy: 0.8044\n",
      "Epoch 743/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4480 - accuracy: 0.7935 - val_loss: 0.4616 - val_accuracy: 0.8044\n",
      "Epoch 744/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.8050 - val_loss: 0.4594 - val_accuracy: 0.8089\n",
      "Epoch 745/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4521 - accuracy: 0.8011 - val_loss: 0.4616 - val_accuracy: 0.8044\n",
      "Epoch 746/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7935 - val_loss: 0.4582 - val_accuracy: 0.8089\n",
      "Epoch 747/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.8050 - val_loss: 0.4569 - val_accuracy: 0.8089\n",
      "Epoch 748/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.7992 - val_loss: 0.4587 - val_accuracy: 0.8089\n",
      "Epoch 749/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4536 - accuracy: 0.7935 - val_loss: 0.4607 - val_accuracy: 0.8044\n",
      "Epoch 750/1600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.4423 - accuracy: 0.8031 - val_loss: 0.4581 - val_accuracy: 0.8089\n",
      "Epoch 751/1600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4433 - accuracy: 0.8069 - val_loss: 0.4593 - val_accuracy: 0.8089\n",
      "Epoch 752/1600\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.4489 - accuracy: 0.7897 - val_loss: 0.4593 - val_accuracy: 0.8089\n",
      "Epoch 753/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4432 - accuracy: 0.8050 - val_loss: 0.4605 - val_accuracy: 0.8089\n",
      "Epoch 754/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4480 - accuracy: 0.7973 - val_loss: 0.4585 - val_accuracy: 0.8178\n",
      "Epoch 755/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4515 - accuracy: 0.7897 - val_loss: 0.4577 - val_accuracy: 0.8044\n",
      "Epoch 756/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4479 - accuracy: 0.7954 - val_loss: 0.4594 - val_accuracy: 0.8044\n",
      "Epoch 757/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4499 - accuracy: 0.8031 - val_loss: 0.4620 - val_accuracy: 0.7956\n",
      "Epoch 758/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4509 - accuracy: 0.8069 - val_loss: 0.4600 - val_accuracy: 0.8044\n",
      "Epoch 759/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4463 - accuracy: 0.7992 - val_loss: 0.4606 - val_accuracy: 0.8044\n",
      "Epoch 760/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.7992 - val_loss: 0.4570 - val_accuracy: 0.8044\n",
      "Epoch 761/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4455 - accuracy: 0.8145 - val_loss: 0.4585 - val_accuracy: 0.8133\n",
      "Epoch 762/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4389 - accuracy: 0.7992 - val_loss: 0.4582 - val_accuracy: 0.8089\n",
      "Epoch 763/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4541 - accuracy: 0.8050 - val_loss: 0.4560 - val_accuracy: 0.8044\n",
      "Epoch 764/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4434 - accuracy: 0.8031 - val_loss: 0.4595 - val_accuracy: 0.7956\n",
      "Epoch 765/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4480 - accuracy: 0.8050 - val_loss: 0.4596 - val_accuracy: 0.8044\n",
      "Epoch 766/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4507 - accuracy: 0.7935 - val_loss: 0.4609 - val_accuracy: 0.7956\n",
      "Epoch 767/1600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.4476 - accuracy: 0.7973 - val_loss: 0.4573 - val_accuracy: 0.8044\n",
      "Epoch 768/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4479 - accuracy: 0.8011 - val_loss: 0.4600 - val_accuracy: 0.8089\n",
      "Epoch 769/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.8050 - val_loss: 0.4596 - val_accuracy: 0.8089\n",
      "Epoch 770/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.8031 - val_loss: 0.4597 - val_accuracy: 0.8089\n",
      "Epoch 771/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.8011 - val_loss: 0.4611 - val_accuracy: 0.7956\n",
      "Epoch 772/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7954 - val_loss: 0.4590 - val_accuracy: 0.8089\n",
      "Epoch 773/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7935 - val_loss: 0.4595 - val_accuracy: 0.8044\n",
      "Epoch 774/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.8011 - val_loss: 0.4572 - val_accuracy: 0.8044\n",
      "Epoch 775/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7992 - val_loss: 0.4609 - val_accuracy: 0.7956\n",
      "Epoch 776/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.8031 - val_loss: 0.4580 - val_accuracy: 0.8089\n",
      "Epoch 777/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7973 - val_loss: 0.4583 - val_accuracy: 0.8089\n",
      "Epoch 778/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7916 - val_loss: 0.4609 - val_accuracy: 0.8089\n",
      "Epoch 779/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7954 - val_loss: 0.4603 - val_accuracy: 0.8044\n",
      "Epoch 780/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.8088 - val_loss: 0.4598 - val_accuracy: 0.8000\n",
      "Epoch 781/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4515 - accuracy: 0.7916 - val_loss: 0.4589 - val_accuracy: 0.8000\n",
      "Epoch 782/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.8011 - val_loss: 0.4593 - val_accuracy: 0.8089\n",
      "Epoch 783/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4532 - accuracy: 0.7935 - val_loss: 0.4583 - val_accuracy: 0.8089\n",
      "Epoch 784/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4483 - accuracy: 0.8069 - val_loss: 0.4597 - val_accuracy: 0.8089\n",
      "Epoch 785/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4520 - accuracy: 0.7992 - val_loss: 0.4603 - val_accuracy: 0.8044\n",
      "Epoch 786/1600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4485 - accuracy: 0.7973 - val_loss: 0.4609 - val_accuracy: 0.8044\n",
      "Epoch 787/1600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4505 - accuracy: 0.8069 - val_loss: 0.4582 - val_accuracy: 0.8089\n",
      "Epoch 788/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4474 - accuracy: 0.8069 - val_loss: 0.4623 - val_accuracy: 0.8044\n",
      "Epoch 789/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4478 - accuracy: 0.8050 - val_loss: 0.4586 - val_accuracy: 0.8089\n",
      "Epoch 790/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4513 - accuracy: 0.7973 - val_loss: 0.4592 - val_accuracy: 0.8133\n",
      "Epoch 791/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4494 - accuracy: 0.7954 - val_loss: 0.4571 - val_accuracy: 0.8089\n",
      "Epoch 792/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4462 - accuracy: 0.7973 - val_loss: 0.4577 - val_accuracy: 0.8089\n",
      "Epoch 793/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4468 - accuracy: 0.7973 - val_loss: 0.4591 - val_accuracy: 0.8089\n",
      "Epoch 794/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4485 - accuracy: 0.7973 - val_loss: 0.4587 - val_accuracy: 0.8178\n",
      "Epoch 795/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4472 - accuracy: 0.8031 - val_loss: 0.4592 - val_accuracy: 0.8089\n",
      "Epoch 796/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4489 - accuracy: 0.8011 - val_loss: 0.4578 - val_accuracy: 0.8044\n",
      "Epoch 797/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4519 - accuracy: 0.7992 - val_loss: 0.4566 - val_accuracy: 0.8089\n",
      "Epoch 798/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.8011 - val_loss: 0.4574 - val_accuracy: 0.8044\n",
      "Epoch 799/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4491 - accuracy: 0.7935 - val_loss: 0.4585 - val_accuracy: 0.8089\n",
      "Epoch 800/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.8011 - val_loss: 0.4591 - val_accuracy: 0.8133\n",
      "Epoch 801/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.7935 - val_loss: 0.4605 - val_accuracy: 0.8089\n",
      "Epoch 802/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4520 - accuracy: 0.7954 - val_loss: 0.4600 - val_accuracy: 0.8089\n",
      "Epoch 803/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7935 - val_loss: 0.4603 - val_accuracy: 0.8044\n",
      "Epoch 804/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7992 - val_loss: 0.4593 - val_accuracy: 0.8133\n",
      "Epoch 805/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.7954 - val_loss: 0.4587 - val_accuracy: 0.8044\n",
      "Epoch 806/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.8050 - val_loss: 0.4602 - val_accuracy: 0.8044\n",
      "Epoch 807/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7935 - val_loss: 0.4618 - val_accuracy: 0.8133\n",
      "Epoch 808/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.8011 - val_loss: 0.4654 - val_accuracy: 0.8044\n",
      "Epoch 809/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.8107 - val_loss: 0.4615 - val_accuracy: 0.8089\n",
      "Epoch 810/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.8050 - val_loss: 0.4606 - val_accuracy: 0.8000\n",
      "Epoch 811/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.8011 - val_loss: 0.4582 - val_accuracy: 0.8089\n",
      "Epoch 812/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.8031 - val_loss: 0.4576 - val_accuracy: 0.8133\n",
      "Epoch 813/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4516 - accuracy: 0.7935 - val_loss: 0.4582 - val_accuracy: 0.8044\n",
      "Epoch 814/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4450 - accuracy: 0.8050 - val_loss: 0.4619 - val_accuracy: 0.8000\n",
      "Epoch 815/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.8031 - val_loss: 0.4607 - val_accuracy: 0.8044\n",
      "Epoch 816/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.7935 - val_loss: 0.4603 - val_accuracy: 0.8044\n",
      "Epoch 817/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7992 - val_loss: 0.4585 - val_accuracy: 0.8044\n",
      "Epoch 818/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7839 - val_loss: 0.4592 - val_accuracy: 0.8089\n",
      "Epoch 819/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4480 - accuracy: 0.8050 - val_loss: 0.4622 - val_accuracy: 0.8044\n",
      "Epoch 820/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7897 - val_loss: 0.4586 - val_accuracy: 0.8089\n",
      "Epoch 821/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4452 - accuracy: 0.7992 - val_loss: 0.4574 - val_accuracy: 0.8089\n",
      "Epoch 822/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.8011 - val_loss: 0.4593 - val_accuracy: 0.8089\n",
      "Epoch 823/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.8050 - val_loss: 0.4648 - val_accuracy: 0.8044\n",
      "Epoch 824/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4524 - accuracy: 0.7954 - val_loss: 0.4613 - val_accuracy: 0.8000\n",
      "Epoch 825/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7973 - val_loss: 0.4604 - val_accuracy: 0.8089\n",
      "Epoch 826/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.8050 - val_loss: 0.4589 - val_accuracy: 0.8089\n",
      "Epoch 827/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7935 - val_loss: 0.4584 - val_accuracy: 0.8044\n",
      "Epoch 828/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.8011 - val_loss: 0.4582 - val_accuracy: 0.8133\n",
      "Epoch 829/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4457 - accuracy: 0.7992 - val_loss: 0.4591 - val_accuracy: 0.8178\n",
      "Epoch 830/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.8088 - val_loss: 0.4584 - val_accuracy: 0.8044\n",
      "Epoch 831/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7935 - val_loss: 0.4594 - val_accuracy: 0.8089\n",
      "Epoch 832/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4502 - accuracy: 0.7954 - val_loss: 0.4630 - val_accuracy: 0.8044\n",
      "Epoch 833/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.7992 - val_loss: 0.4588 - val_accuracy: 0.8044\n",
      "Epoch 834/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.8050 - val_loss: 0.4615 - val_accuracy: 0.8044\n",
      "Epoch 835/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.8050 - val_loss: 0.4609 - val_accuracy: 0.8044\n",
      "Epoch 836/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.8011 - val_loss: 0.4614 - val_accuracy: 0.8000\n",
      "Epoch 837/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.8011 - val_loss: 0.4642 - val_accuracy: 0.8044\n",
      "Epoch 838/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7973 - val_loss: 0.4614 - val_accuracy: 0.8089\n",
      "Epoch 839/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4479 - accuracy: 0.7992 - val_loss: 0.4610 - val_accuracy: 0.8133\n",
      "Epoch 840/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.8088 - val_loss: 0.4622 - val_accuracy: 0.8089\n",
      "Epoch 841/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4454 - accuracy: 0.8011 - val_loss: 0.4625 - val_accuracy: 0.8044\n",
      "Epoch 842/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.8011 - val_loss: 0.4617 - val_accuracy: 0.8044\n",
      "Epoch 843/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4478 - accuracy: 0.7935 - val_loss: 0.4627 - val_accuracy: 0.8133\n",
      "Epoch 844/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4462 - accuracy: 0.8011 - val_loss: 0.4617 - val_accuracy: 0.8044\n",
      "Epoch 845/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.7897 - val_loss: 0.4630 - val_accuracy: 0.8044\n",
      "Epoch 846/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.7954 - val_loss: 0.4627 - val_accuracy: 0.8000\n",
      "Epoch 847/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7973 - val_loss: 0.4623 - val_accuracy: 0.8133\n",
      "Epoch 848/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7897 - val_loss: 0.4622 - val_accuracy: 0.8089\n",
      "Epoch 849/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.8011 - val_loss: 0.4601 - val_accuracy: 0.8089\n",
      "Epoch 850/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.8050 - val_loss: 0.4623 - val_accuracy: 0.8133\n",
      "Epoch 851/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4479 - accuracy: 0.7973 - val_loss: 0.4649 - val_accuracy: 0.7956\n",
      "Epoch 852/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4472 - accuracy: 0.8011 - val_loss: 0.4650 - val_accuracy: 0.7956\n",
      "Epoch 853/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7992 - val_loss: 0.4625 - val_accuracy: 0.8044\n",
      "Epoch 854/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.8069 - val_loss: 0.4613 - val_accuracy: 0.8089\n",
      "Epoch 855/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.8069 - val_loss: 0.4590 - val_accuracy: 0.8044\n",
      "Epoch 856/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.8031 - val_loss: 0.4591 - val_accuracy: 0.8133\n",
      "Epoch 857/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4470 - accuracy: 0.8050 - val_loss: 0.4625 - val_accuracy: 0.8000\n",
      "Epoch 858/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.7973 - val_loss: 0.4618 - val_accuracy: 0.8089\n",
      "Epoch 859/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7992 - val_loss: 0.4612 - val_accuracy: 0.8044\n",
      "Epoch 860/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7973 - val_loss: 0.4612 - val_accuracy: 0.8178\n",
      "Epoch 861/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7992 - val_loss: 0.4629 - val_accuracy: 0.8000\n",
      "Epoch 862/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.8069 - val_loss: 0.4618 - val_accuracy: 0.8089\n",
      "Epoch 863/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4454 - accuracy: 0.7992 - val_loss: 0.4634 - val_accuracy: 0.7956\n",
      "Epoch 864/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.8011 - val_loss: 0.4593 - val_accuracy: 0.8089\n",
      "Epoch 865/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7954 - val_loss: 0.4600 - val_accuracy: 0.8089\n",
      "Epoch 866/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.8069 - val_loss: 0.4596 - val_accuracy: 0.8044\n",
      "Epoch 867/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.8011 - val_loss: 0.4599 - val_accuracy: 0.8089\n",
      "Epoch 868/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.7897 - val_loss: 0.4598 - val_accuracy: 0.8044\n",
      "Epoch 869/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7973 - val_loss: 0.4603 - val_accuracy: 0.8044\n",
      "Epoch 870/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.8011 - val_loss: 0.4605 - val_accuracy: 0.8089\n",
      "Epoch 871/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7935 - val_loss: 0.4599 - val_accuracy: 0.8044\n",
      "Epoch 872/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.8069 - val_loss: 0.4609 - val_accuracy: 0.8133\n",
      "Epoch 873/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.8088 - val_loss: 0.4599 - val_accuracy: 0.8044\n",
      "Epoch 874/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4474 - accuracy: 0.8031 - val_loss: 0.4626 - val_accuracy: 0.8000\n",
      "Epoch 875/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7897 - val_loss: 0.4598 - val_accuracy: 0.8133\n",
      "Epoch 876/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7954 - val_loss: 0.4601 - val_accuracy: 0.8089\n",
      "Epoch 877/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7973 - val_loss: 0.4602 - val_accuracy: 0.8089\n",
      "Epoch 878/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.8011 - val_loss: 0.4605 - val_accuracy: 0.8178\n",
      "Epoch 879/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7973 - val_loss: 0.4597 - val_accuracy: 0.8044\n",
      "Epoch 880/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.8011 - val_loss: 0.4589 - val_accuracy: 0.8089\n",
      "Epoch 881/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.8069 - val_loss: 0.4611 - val_accuracy: 0.8089\n",
      "Epoch 882/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4492 - accuracy: 0.7973 - val_loss: 0.4606 - val_accuracy: 0.8089\n",
      "Epoch 883/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4496 - accuracy: 0.8011 - val_loss: 0.4611 - val_accuracy: 0.8089\n",
      "Epoch 884/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.8069 - val_loss: 0.4589 - val_accuracy: 0.8044\n",
      "Epoch 885/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.7954 - val_loss: 0.4590 - val_accuracy: 0.8044\n",
      "Epoch 886/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.7935 - val_loss: 0.4612 - val_accuracy: 0.8089\n",
      "Epoch 887/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7916 - val_loss: 0.4610 - val_accuracy: 0.8089\n",
      "Epoch 888/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.7954 - val_loss: 0.4614 - val_accuracy: 0.8000\n",
      "Epoch 889/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.8069 - val_loss: 0.4618 - val_accuracy: 0.8044\n",
      "Epoch 890/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.7954 - val_loss: 0.4643 - val_accuracy: 0.8000\n",
      "Epoch 891/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.7992 - val_loss: 0.4613 - val_accuracy: 0.8089\n",
      "Epoch 892/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.7954 - val_loss: 0.4624 - val_accuracy: 0.8089\n",
      "Epoch 893/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7954 - val_loss: 0.4626 - val_accuracy: 0.8044\n",
      "Epoch 894/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.8011 - val_loss: 0.4618 - val_accuracy: 0.8089\n",
      "Epoch 895/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7992 - val_loss: 0.4593 - val_accuracy: 0.8044\n",
      "Epoch 896/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.8031 - val_loss: 0.4595 - val_accuracy: 0.8044\n",
      "Epoch 897/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.8031 - val_loss: 0.4593 - val_accuracy: 0.8044\n",
      "Epoch 898/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.8031 - val_loss: 0.4600 - val_accuracy: 0.8044\n",
      "Epoch 899/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7916 - val_loss: 0.4589 - val_accuracy: 0.8089\n",
      "Epoch 900/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7973 - val_loss: 0.4590 - val_accuracy: 0.8000\n",
      "Epoch 901/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.7973 - val_loss: 0.4612 - val_accuracy: 0.8000\n",
      "Epoch 902/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.8069 - val_loss: 0.4616 - val_accuracy: 0.8089\n",
      "Epoch 903/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.8069 - val_loss: 0.4602 - val_accuracy: 0.8000\n",
      "Epoch 904/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.8011 - val_loss: 0.4592 - val_accuracy: 0.8089\n",
      "Epoch 905/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4515 - accuracy: 0.8069 - val_loss: 0.4608 - val_accuracy: 0.8044\n",
      "Epoch 906/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7954 - val_loss: 0.4598 - val_accuracy: 0.8133\n",
      "Epoch 907/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7992 - val_loss: 0.4603 - val_accuracy: 0.8044\n",
      "Epoch 908/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7973 - val_loss: 0.4590 - val_accuracy: 0.8044\n",
      "Epoch 909/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7916 - val_loss: 0.4633 - val_accuracy: 0.8089\n",
      "Epoch 910/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7992 - val_loss: 0.4594 - val_accuracy: 0.8089\n",
      "Epoch 911/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.8011 - val_loss: 0.4614 - val_accuracy: 0.8044\n",
      "Epoch 912/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.8031 - val_loss: 0.4610 - val_accuracy: 0.8089\n",
      "Epoch 913/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4472 - accuracy: 0.7992 - val_loss: 0.4630 - val_accuracy: 0.8044\n",
      "Epoch 914/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.8031 - val_loss: 0.4608 - val_accuracy: 0.8044\n",
      "Epoch 915/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4526 - accuracy: 0.7954 - val_loss: 0.4639 - val_accuracy: 0.8000\n",
      "Epoch 916/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4423 - accuracy: 0.8069 - val_loss: 0.4638 - val_accuracy: 0.8089\n",
      "Epoch 917/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.7954 - val_loss: 0.4635 - val_accuracy: 0.8133\n",
      "Epoch 918/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7992 - val_loss: 0.4646 - val_accuracy: 0.8089\n",
      "Epoch 919/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7954 - val_loss: 0.4632 - val_accuracy: 0.8089\n",
      "Epoch 920/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4496 - accuracy: 0.7954 - val_loss: 0.4632 - val_accuracy: 0.8044\n",
      "Epoch 921/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7992 - val_loss: 0.4641 - val_accuracy: 0.8000\n",
      "Epoch 922/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.7992 - val_loss: 0.4623 - val_accuracy: 0.8044\n",
      "Epoch 923/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.8088 - val_loss: 0.4610 - val_accuracy: 0.8089\n",
      "Epoch 924/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7954 - val_loss: 0.4626 - val_accuracy: 0.8089\n",
      "Epoch 925/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.8031 - val_loss: 0.4604 - val_accuracy: 0.8044\n",
      "Epoch 926/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.8069 - val_loss: 0.4631 - val_accuracy: 0.8044\n",
      "Epoch 927/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7992 - val_loss: 0.4603 - val_accuracy: 0.8044\n",
      "Epoch 928/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.8031 - val_loss: 0.4621 - val_accuracy: 0.8044\n",
      "Epoch 929/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7992 - val_loss: 0.4660 - val_accuracy: 0.7956\n",
      "Epoch 930/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.8011 - val_loss: 0.4641 - val_accuracy: 0.8089\n",
      "Epoch 931/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7954 - val_loss: 0.4649 - val_accuracy: 0.8044\n",
      "Epoch 932/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.8050 - val_loss: 0.4627 - val_accuracy: 0.8044\n",
      "Epoch 933/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.8050 - val_loss: 0.4607 - val_accuracy: 0.8089\n",
      "Epoch 934/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.8050 - val_loss: 0.4602 - val_accuracy: 0.8133\n",
      "Epoch 935/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7973 - val_loss: 0.4644 - val_accuracy: 0.8044\n",
      "Epoch 936/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.7992 - val_loss: 0.4639 - val_accuracy: 0.8089\n",
      "Epoch 937/1600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4448 - accuracy: 0.7973 - val_loss: 0.4630 - val_accuracy: 0.8089\n",
      "Epoch 938/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7973 - val_loss: 0.4621 - val_accuracy: 0.8044\n",
      "Epoch 939/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.8011 - val_loss: 0.4633 - val_accuracy: 0.8089\n",
      "Epoch 940/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.8031 - val_loss: 0.4609 - val_accuracy: 0.8044\n",
      "Epoch 941/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.8050 - val_loss: 0.4597 - val_accuracy: 0.8089\n",
      "Epoch 942/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.8050 - val_loss: 0.4616 - val_accuracy: 0.8044\n",
      "Epoch 943/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.8069 - val_loss: 0.4605 - val_accuracy: 0.8044\n",
      "Epoch 944/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7878 - val_loss: 0.4604 - val_accuracy: 0.8044\n",
      "Epoch 945/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7992 - val_loss: 0.4629 - val_accuracy: 0.8044\n",
      "Epoch 946/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.8011 - val_loss: 0.4647 - val_accuracy: 0.7956\n",
      "Epoch 947/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7992 - val_loss: 0.4611 - val_accuracy: 0.8089\n",
      "Epoch 948/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4466 - accuracy: 0.8011 - val_loss: 0.4631 - val_accuracy: 0.8044\n",
      "Epoch 949/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.8050 - val_loss: 0.4627 - val_accuracy: 0.8089\n",
      "Epoch 950/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7973 - val_loss: 0.4610 - val_accuracy: 0.8044\n",
      "Epoch 951/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.8011 - val_loss: 0.4641 - val_accuracy: 0.8044\n",
      "Epoch 952/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.8050 - val_loss: 0.4628 - val_accuracy: 0.8133\n",
      "Epoch 953/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4482 - accuracy: 0.7916 - val_loss: 0.4598 - val_accuracy: 0.8044\n",
      "Epoch 954/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.8011 - val_loss: 0.4652 - val_accuracy: 0.8044\n",
      "Epoch 955/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.8031 - val_loss: 0.4646 - val_accuracy: 0.8044\n",
      "Epoch 956/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.8031 - val_loss: 0.4625 - val_accuracy: 0.8089\n",
      "Epoch 957/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.8069 - val_loss: 0.4612 - val_accuracy: 0.8133\n",
      "Epoch 958/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4463 - accuracy: 0.8011 - val_loss: 0.4630 - val_accuracy: 0.7956\n",
      "Epoch 959/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4468 - accuracy: 0.8050 - val_loss: 0.4622 - val_accuracy: 0.8044\n",
      "Epoch 960/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.8031 - val_loss: 0.4632 - val_accuracy: 0.8044\n",
      "Epoch 961/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.7992 - val_loss: 0.4632 - val_accuracy: 0.8044\n",
      "Epoch 962/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.7973 - val_loss: 0.4620 - val_accuracy: 0.8089\n",
      "Epoch 963/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7973 - val_loss: 0.4649 - val_accuracy: 0.8000\n",
      "Epoch 964/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.7954 - val_loss: 0.4644 - val_accuracy: 0.8000\n",
      "Epoch 965/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.7992 - val_loss: 0.4644 - val_accuracy: 0.8044\n",
      "Epoch 966/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.7992 - val_loss: 0.4634 - val_accuracy: 0.8044\n",
      "Epoch 967/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4480 - accuracy: 0.7954 - val_loss: 0.4645 - val_accuracy: 0.8000\n",
      "Epoch 968/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.8011 - val_loss: 0.4634 - val_accuracy: 0.8133\n",
      "Epoch 969/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.8011 - val_loss: 0.4594 - val_accuracy: 0.8044\n",
      "Epoch 970/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.7973 - val_loss: 0.4608 - val_accuracy: 0.8044\n",
      "Epoch 971/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4424 - accuracy: 0.8050 - val_loss: 0.4623 - val_accuracy: 0.8044\n",
      "Epoch 972/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4520 - accuracy: 0.7973 - val_loss: 0.4604 - val_accuracy: 0.8089\n",
      "Epoch 973/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.8069 - val_loss: 0.4608 - val_accuracy: 0.8044\n",
      "Epoch 974/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.8088 - val_loss: 0.4642 - val_accuracy: 0.8000\n",
      "Epoch 975/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.8031 - val_loss: 0.4641 - val_accuracy: 0.8000\n",
      "Epoch 976/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7992 - val_loss: 0.4633 - val_accuracy: 0.8089\n",
      "Epoch 977/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4463 - accuracy: 0.8031 - val_loss: 0.4662 - val_accuracy: 0.8044\n",
      "Epoch 978/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4463 - accuracy: 0.7992 - val_loss: 0.4625 - val_accuracy: 0.8089\n",
      "Epoch 979/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4491 - accuracy: 0.8088 - val_loss: 0.4661 - val_accuracy: 0.8089\n",
      "Epoch 980/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.8050 - val_loss: 0.4637 - val_accuracy: 0.8044\n",
      "Epoch 981/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.8069 - val_loss: 0.4627 - val_accuracy: 0.8044\n",
      "Epoch 982/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4481 - accuracy: 0.8069 - val_loss: 0.4649 - val_accuracy: 0.8044\n",
      "Epoch 983/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.8011 - val_loss: 0.4643 - val_accuracy: 0.8133\n",
      "Epoch 984/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.8088 - val_loss: 0.4630 - val_accuracy: 0.8044\n",
      "Epoch 985/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4422 - accuracy: 0.8011 - val_loss: 0.4641 - val_accuracy: 0.8089\n",
      "Epoch 986/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7992 - val_loss: 0.4650 - val_accuracy: 0.8044\n",
      "Epoch 987/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4434 - accuracy: 0.8011 - val_loss: 0.4655 - val_accuracy: 0.8044\n",
      "Epoch 988/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.8145 - val_loss: 0.4635 - val_accuracy: 0.8044\n",
      "Epoch 989/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.8050 - val_loss: 0.4614 - val_accuracy: 0.8044\n",
      "Epoch 990/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.7973 - val_loss: 0.4593 - val_accuracy: 0.8044\n",
      "Epoch 991/1600\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.4472 - accuracy: 0.8011 - val_loss: 0.4641 - val_accuracy: 0.8089\n",
      "Epoch 992/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.7992 - val_loss: 0.4625 - val_accuracy: 0.8044\n",
      "Epoch 993/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.8031 - val_loss: 0.4630 - val_accuracy: 0.8000\n",
      "Epoch 994/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4446 - accuracy: 0.8011 - val_loss: 0.4628 - val_accuracy: 0.8044\n",
      "Epoch 995/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4361 - accuracy: 0.8107 - val_loss: 0.4632 - val_accuracy: 0.8044\n",
      "Epoch 996/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4439 - accuracy: 0.8088 - val_loss: 0.4652 - val_accuracy: 0.8044\n",
      "Epoch 997/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.8050 - val_loss: 0.4614 - val_accuracy: 0.8044\n",
      "Epoch 998/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.8011 - val_loss: 0.4608 - val_accuracy: 0.8044\n",
      "Epoch 999/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.8069 - val_loss: 0.4619 - val_accuracy: 0.8089\n",
      "Epoch 1000/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4529 - accuracy: 0.8031 - val_loss: 0.4636 - val_accuracy: 0.8044\n",
      "Epoch 1001/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4431 - accuracy: 0.7992 - val_loss: 0.4651 - val_accuracy: 0.8000\n",
      "Epoch 1002/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4439 - accuracy: 0.8031 - val_loss: 0.4640 - val_accuracy: 0.8000\n",
      "Epoch 1003/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4432 - accuracy: 0.8050 - val_loss: 0.4616 - val_accuracy: 0.8044\n",
      "Epoch 1004/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4453 - accuracy: 0.8031 - val_loss: 0.4626 - val_accuracy: 0.8044\n",
      "Epoch 1005/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4454 - accuracy: 0.8069 - val_loss: 0.4614 - val_accuracy: 0.8044\n",
      "Epoch 1006/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4409 - accuracy: 0.8088 - val_loss: 0.4621 - val_accuracy: 0.8044\n",
      "Epoch 1007/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4385 - accuracy: 0.8069 - val_loss: 0.4630 - val_accuracy: 0.8044\n",
      "Epoch 1008/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4466 - accuracy: 0.8031 - val_loss: 0.4613 - val_accuracy: 0.8044\n",
      "Epoch 1009/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4447 - accuracy: 0.8031 - val_loss: 0.4626 - val_accuracy: 0.8044\n",
      "Epoch 1010/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4441 - accuracy: 0.8031 - val_loss: 0.4636 - val_accuracy: 0.8044\n",
      "Epoch 1011/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4415 - accuracy: 0.8069 - val_loss: 0.4616 - val_accuracy: 0.8044\n",
      "Epoch 1012/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4423 - accuracy: 0.8011 - val_loss: 0.4623 - val_accuracy: 0.8044\n",
      "Epoch 1013/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.8031 - val_loss: 0.4614 - val_accuracy: 0.8044\n",
      "Epoch 1014/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.8011 - val_loss: 0.4614 - val_accuracy: 0.8044\n",
      "Epoch 1015/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.8050 - val_loss: 0.4627 - val_accuracy: 0.8000\n",
      "Epoch 1016/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7992 - val_loss: 0.4628 - val_accuracy: 0.8044\n",
      "Epoch 1017/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.8145 - val_loss: 0.4637 - val_accuracy: 0.8044\n",
      "Epoch 1018/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.8050 - val_loss: 0.4640 - val_accuracy: 0.8044\n",
      "Epoch 1019/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.8126 - val_loss: 0.4658 - val_accuracy: 0.8000\n",
      "Epoch 1020/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.8069 - val_loss: 0.4627 - val_accuracy: 0.8000\n",
      "Epoch 1021/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.8069 - val_loss: 0.4637 - val_accuracy: 0.7956\n",
      "Epoch 1022/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.8107 - val_loss: 0.4621 - val_accuracy: 0.8044\n",
      "Epoch 1023/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.8031 - val_loss: 0.4643 - val_accuracy: 0.8000\n",
      "Epoch 1024/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.8031 - val_loss: 0.4604 - val_accuracy: 0.8133\n",
      "Epoch 1025/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4418 - accuracy: 0.8069 - val_loss: 0.4642 - val_accuracy: 0.8044\n",
      "Epoch 1026/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.8031 - val_loss: 0.4644 - val_accuracy: 0.8044\n",
      "Epoch 1027/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7992 - val_loss: 0.4621 - val_accuracy: 0.8089\n",
      "Epoch 1028/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7992 - val_loss: 0.4660 - val_accuracy: 0.8000\n",
      "Epoch 1029/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.7973 - val_loss: 0.4622 - val_accuracy: 0.8089\n",
      "Epoch 1030/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7992 - val_loss: 0.4618 - val_accuracy: 0.8089\n",
      "Epoch 1031/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.7973 - val_loss: 0.4649 - val_accuracy: 0.7956\n",
      "Epoch 1032/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.8088 - val_loss: 0.4640 - val_accuracy: 0.8044\n",
      "Epoch 1033/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.8011 - val_loss: 0.4640 - val_accuracy: 0.8000\n",
      "Epoch 1034/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.8031 - val_loss: 0.4634 - val_accuracy: 0.8000\n",
      "Epoch 1035/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.7954 - val_loss: 0.4610 - val_accuracy: 0.8133\n",
      "Epoch 1036/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.8145 - val_loss: 0.4629 - val_accuracy: 0.8044\n",
      "Epoch 1037/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.8011 - val_loss: 0.4625 - val_accuracy: 0.8089\n",
      "Epoch 1038/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.8031 - val_loss: 0.4632 - val_accuracy: 0.8044\n",
      "Epoch 1039/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.7992 - val_loss: 0.4634 - val_accuracy: 0.8044\n",
      "Epoch 1040/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.8069 - val_loss: 0.4622 - val_accuracy: 0.8000\n",
      "Epoch 1041/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.8088 - val_loss: 0.4636 - val_accuracy: 0.8044\n",
      "Epoch 1042/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4443 - accuracy: 0.8069 - val_loss: 0.4627 - val_accuracy: 0.8089\n",
      "Epoch 1043/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.8088 - val_loss: 0.4641 - val_accuracy: 0.8000\n",
      "Epoch 1044/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.8107 - val_loss: 0.4612 - val_accuracy: 0.8044\n",
      "Epoch 1045/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.8107 - val_loss: 0.4608 - val_accuracy: 0.8044\n",
      "Epoch 1046/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.8069 - val_loss: 0.4642 - val_accuracy: 0.8044\n",
      "Epoch 1047/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.8069 - val_loss: 0.4632 - val_accuracy: 0.8044\n",
      "Epoch 1048/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.8011 - val_loss: 0.4631 - val_accuracy: 0.8000\n",
      "Epoch 1049/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.8069 - val_loss: 0.4615 - val_accuracy: 0.8044\n",
      "Epoch 1050/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7954 - val_loss: 0.4622 - val_accuracy: 0.8044\n",
      "Epoch 1051/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7992 - val_loss: 0.4648 - val_accuracy: 0.8044\n",
      "Epoch 1052/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.8031 - val_loss: 0.4635 - val_accuracy: 0.8089\n",
      "Epoch 1053/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.8069 - val_loss: 0.4617 - val_accuracy: 0.8044\n",
      "Epoch 1054/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.8069 - val_loss: 0.4623 - val_accuracy: 0.8044\n",
      "Epoch 1055/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.8031 - val_loss: 0.4623 - val_accuracy: 0.8044\n",
      "Epoch 1056/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.8031 - val_loss: 0.4622 - val_accuracy: 0.8044\n",
      "Epoch 1057/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.8031 - val_loss: 0.4646 - val_accuracy: 0.8000\n",
      "Epoch 1058/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.7935 - val_loss: 0.4650 - val_accuracy: 0.8000\n",
      "Epoch 1059/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.8031 - val_loss: 0.4612 - val_accuracy: 0.8044\n",
      "Epoch 1060/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.8107 - val_loss: 0.4643 - val_accuracy: 0.8044\n",
      "Epoch 1061/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.8164 - val_loss: 0.4647 - val_accuracy: 0.8044\n",
      "Epoch 1062/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.8031 - val_loss: 0.4641 - val_accuracy: 0.8044\n",
      "Epoch 1063/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4432 - accuracy: 0.8069 - val_loss: 0.4646 - val_accuracy: 0.8044\n",
      "Epoch 1064/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.8031 - val_loss: 0.4651 - val_accuracy: 0.7956\n",
      "Epoch 1065/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7992 - val_loss: 0.4646 - val_accuracy: 0.8044\n",
      "Epoch 1066/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.7973 - val_loss: 0.4643 - val_accuracy: 0.8000\n",
      "Epoch 1067/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.8050 - val_loss: 0.4643 - val_accuracy: 0.8000\n",
      "Epoch 1068/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.8050 - val_loss: 0.4644 - val_accuracy: 0.8044\n",
      "Epoch 1069/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.8011 - val_loss: 0.4679 - val_accuracy: 0.8000\n",
      "Epoch 1070/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4418 - accuracy: 0.7954 - val_loss: 0.4651 - val_accuracy: 0.8089\n",
      "Epoch 1071/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7992 - val_loss: 0.4653 - val_accuracy: 0.8044\n",
      "Epoch 1072/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.8088 - val_loss: 0.4627 - val_accuracy: 0.8044\n",
      "Epoch 1073/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4457 - accuracy: 0.8088 - val_loss: 0.4636 - val_accuracy: 0.8044\n",
      "Epoch 1074/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4498 - accuracy: 0.7973 - val_loss: 0.4642 - val_accuracy: 0.8089\n",
      "Epoch 1075/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7973 - val_loss: 0.4659 - val_accuracy: 0.8089\n",
      "Epoch 1076/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.8031 - val_loss: 0.4663 - val_accuracy: 0.8044\n",
      "Epoch 1077/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.8050 - val_loss: 0.4674 - val_accuracy: 0.8044\n",
      "Epoch 1078/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.8031 - val_loss: 0.4646 - val_accuracy: 0.8000\n",
      "Epoch 1079/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7973 - val_loss: 0.4664 - val_accuracy: 0.8044\n",
      "Epoch 1080/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.8011 - val_loss: 0.4630 - val_accuracy: 0.8089\n",
      "Epoch 1081/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.8069 - val_loss: 0.4628 - val_accuracy: 0.8133\n",
      "Epoch 1082/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8050 - val_loss: 0.4630 - val_accuracy: 0.8044\n",
      "Epoch 1083/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.8107 - val_loss: 0.4641 - val_accuracy: 0.8044\n",
      "Epoch 1084/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7992 - val_loss: 0.4669 - val_accuracy: 0.8000\n",
      "Epoch 1085/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.8011 - val_loss: 0.4651 - val_accuracy: 0.8044\n",
      "Epoch 1086/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.8069 - val_loss: 0.4636 - val_accuracy: 0.8044\n",
      "Epoch 1087/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.8069 - val_loss: 0.4613 - val_accuracy: 0.8044\n",
      "Epoch 1088/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.8145 - val_loss: 0.4647 - val_accuracy: 0.8000\n",
      "Epoch 1089/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.8031 - val_loss: 0.4650 - val_accuracy: 0.8000\n",
      "Epoch 1090/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.8107 - val_loss: 0.4656 - val_accuracy: 0.8044\n",
      "Epoch 1091/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4460 - accuracy: 0.8050 - val_loss: 0.4673 - val_accuracy: 0.8044\n",
      "Epoch 1092/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4385 - accuracy: 0.8145 - val_loss: 0.4647 - val_accuracy: 0.8044\n",
      "Epoch 1093/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4376 - accuracy: 0.8050 - val_loss: 0.4640 - val_accuracy: 0.8044\n",
      "Epoch 1094/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.8011 - val_loss: 0.4642 - val_accuracy: 0.8044\n",
      "Epoch 1095/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7973 - val_loss: 0.4652 - val_accuracy: 0.8044\n",
      "Epoch 1096/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.8069 - val_loss: 0.4648 - val_accuracy: 0.8044\n",
      "Epoch 1097/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7992 - val_loss: 0.4655 - val_accuracy: 0.8044\n",
      "Epoch 1098/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.8011 - val_loss: 0.4657 - val_accuracy: 0.8044\n",
      "Epoch 1099/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.8011 - val_loss: 0.4634 - val_accuracy: 0.8044\n",
      "Epoch 1100/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.8069 - val_loss: 0.4651 - val_accuracy: 0.8044\n",
      "Epoch 1101/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4444 - accuracy: 0.8069 - val_loss: 0.4659 - val_accuracy: 0.8000\n",
      "Epoch 1102/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.8069 - val_loss: 0.4661 - val_accuracy: 0.8044\n",
      "Epoch 1103/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.8050 - val_loss: 0.4647 - val_accuracy: 0.8089\n",
      "Epoch 1104/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.8011 - val_loss: 0.4671 - val_accuracy: 0.8000\n",
      "Epoch 1105/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4427 - accuracy: 0.8011 - val_loss: 0.4649 - val_accuracy: 0.8089\n",
      "Epoch 1106/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.8031 - val_loss: 0.4631 - val_accuracy: 0.8133\n",
      "Epoch 1107/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.7897 - val_loss: 0.4677 - val_accuracy: 0.8089\n",
      "Epoch 1108/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.8050 - val_loss: 0.4687 - val_accuracy: 0.8044\n",
      "Epoch 1109/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.8031 - val_loss: 0.4641 - val_accuracy: 0.8089\n",
      "Epoch 1110/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.8069 - val_loss: 0.4664 - val_accuracy: 0.8044\n",
      "Epoch 1111/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4456 - accuracy: 0.8031 - val_loss: 0.4641 - val_accuracy: 0.8044\n",
      "Epoch 1112/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.8050 - val_loss: 0.4678 - val_accuracy: 0.8000\n",
      "Epoch 1113/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.8011 - val_loss: 0.4639 - val_accuracy: 0.8044\n",
      "Epoch 1114/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.7992 - val_loss: 0.4669 - val_accuracy: 0.8044\n",
      "Epoch 1115/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.8011 - val_loss: 0.4671 - val_accuracy: 0.8044\n",
      "Epoch 1116/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.8088 - val_loss: 0.4680 - val_accuracy: 0.8044\n",
      "Epoch 1117/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7954 - val_loss: 0.4647 - val_accuracy: 0.8089\n",
      "Epoch 1118/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.8050 - val_loss: 0.4667 - val_accuracy: 0.8089\n",
      "Epoch 1119/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.8088 - val_loss: 0.4663 - val_accuracy: 0.8089\n",
      "Epoch 1120/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4454 - accuracy: 0.8031 - val_loss: 0.4678 - val_accuracy: 0.8000\n",
      "Epoch 1121/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.8069 - val_loss: 0.4658 - val_accuracy: 0.8044\n",
      "Epoch 1122/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.8088 - val_loss: 0.4647 - val_accuracy: 0.8089\n",
      "Epoch 1123/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.8088 - val_loss: 0.4636 - val_accuracy: 0.8044\n",
      "Epoch 1124/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.8011 - val_loss: 0.4661 - val_accuracy: 0.8133\n",
      "Epoch 1125/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.8011 - val_loss: 0.4647 - val_accuracy: 0.8044\n",
      "Epoch 1126/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.7992 - val_loss: 0.4683 - val_accuracy: 0.8044\n",
      "Epoch 1127/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.8031 - val_loss: 0.4696 - val_accuracy: 0.8000\n",
      "Epoch 1128/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.8050 - val_loss: 0.4689 - val_accuracy: 0.7956\n",
      "Epoch 1129/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4383 - accuracy: 0.8069 - val_loss: 0.4677 - val_accuracy: 0.8044\n",
      "Epoch 1130/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4434 - accuracy: 0.8011 - val_loss: 0.4691 - val_accuracy: 0.8089\n",
      "Epoch 1131/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.8031 - val_loss: 0.4669 - val_accuracy: 0.8044\n",
      "Epoch 1132/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.8107 - val_loss: 0.4646 - val_accuracy: 0.8089\n",
      "Epoch 1133/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4418 - accuracy: 0.8088 - val_loss: 0.4658 - val_accuracy: 0.8000\n",
      "Epoch 1134/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4385 - accuracy: 0.7973 - val_loss: 0.4654 - val_accuracy: 0.8089\n",
      "Epoch 1135/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4450 - accuracy: 0.8088 - val_loss: 0.4693 - val_accuracy: 0.7956\n",
      "Epoch 1136/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4428 - accuracy: 0.8011 - val_loss: 0.4660 - val_accuracy: 0.8089\n",
      "Epoch 1137/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4375 - accuracy: 0.8031 - val_loss: 0.4634 - val_accuracy: 0.8089\n",
      "Epoch 1138/1600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4412 - accuracy: 0.7992 - val_loss: 0.4663 - val_accuracy: 0.8089\n",
      "Epoch 1139/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4407 - accuracy: 0.8069 - val_loss: 0.4642 - val_accuracy: 0.8089\n",
      "Epoch 1140/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4466 - accuracy: 0.7992 - val_loss: 0.4677 - val_accuracy: 0.8044\n",
      "Epoch 1141/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4394 - accuracy: 0.8107 - val_loss: 0.4656 - val_accuracy: 0.8133\n",
      "Epoch 1142/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4417 - accuracy: 0.8050 - val_loss: 0.4669 - val_accuracy: 0.8089\n",
      "Epoch 1143/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4383 - accuracy: 0.7992 - val_loss: 0.4656 - val_accuracy: 0.8089\n",
      "Epoch 1144/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.8145 - val_loss: 0.4667 - val_accuracy: 0.8044\n",
      "Epoch 1145/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7935 - val_loss: 0.4694 - val_accuracy: 0.8000\n",
      "Epoch 1146/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.8050 - val_loss: 0.4663 - val_accuracy: 0.8089\n",
      "Epoch 1147/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4419 - accuracy: 0.8031 - val_loss: 0.4658 - val_accuracy: 0.8044\n",
      "Epoch 1148/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4391 - accuracy: 0.8069 - val_loss: 0.4648 - val_accuracy: 0.8089\n",
      "Epoch 1149/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7992 - val_loss: 0.4648 - val_accuracy: 0.8089\n",
      "Epoch 1150/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.8069 - val_loss: 0.4660 - val_accuracy: 0.8044\n",
      "Epoch 1151/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7954 - val_loss: 0.4658 - val_accuracy: 0.8089\n",
      "Epoch 1152/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.8031 - val_loss: 0.4710 - val_accuracy: 0.7956\n",
      "Epoch 1153/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7992 - val_loss: 0.4625 - val_accuracy: 0.8044\n",
      "Epoch 1154/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.8031 - val_loss: 0.4653 - val_accuracy: 0.8044\n",
      "Epoch 1155/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7992 - val_loss: 0.4663 - val_accuracy: 0.8044\n",
      "Epoch 1156/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.8011 - val_loss: 0.4676 - val_accuracy: 0.8044\n",
      "Epoch 1157/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4397 - accuracy: 0.8011 - val_loss: 0.4679 - val_accuracy: 0.8000\n",
      "Epoch 1158/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4472 - accuracy: 0.8107 - val_loss: 0.4652 - val_accuracy: 0.8044\n",
      "Epoch 1159/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.8126 - val_loss: 0.4657 - val_accuracy: 0.8044\n",
      "Epoch 1160/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7916 - val_loss: 0.4666 - val_accuracy: 0.8044\n",
      "Epoch 1161/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.8050 - val_loss: 0.4655 - val_accuracy: 0.8044\n",
      "Epoch 1162/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.8069 - val_loss: 0.4678 - val_accuracy: 0.8044\n",
      "Epoch 1163/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.8011 - val_loss: 0.4711 - val_accuracy: 0.7956\n",
      "Epoch 1164/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.8031 - val_loss: 0.4662 - val_accuracy: 0.8044\n",
      "Epoch 1165/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.8050 - val_loss: 0.4661 - val_accuracy: 0.8089\n",
      "Epoch 1166/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4373 - accuracy: 0.7935 - val_loss: 0.4679 - val_accuracy: 0.8089\n",
      "Epoch 1167/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4393 - accuracy: 0.7973 - val_loss: 0.4671 - val_accuracy: 0.8089\n",
      "Epoch 1168/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4458 - accuracy: 0.8050 - val_loss: 0.4681 - val_accuracy: 0.8133\n",
      "Epoch 1169/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4381 - accuracy: 0.7992 - val_loss: 0.4683 - val_accuracy: 0.8044\n",
      "Epoch 1170/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.7992 - val_loss: 0.4639 - val_accuracy: 0.8089\n",
      "Epoch 1171/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4383 - accuracy: 0.8031 - val_loss: 0.4642 - val_accuracy: 0.8044\n",
      "Epoch 1172/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4441 - accuracy: 0.8050 - val_loss: 0.4648 - val_accuracy: 0.8089\n",
      "Epoch 1173/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.8050 - val_loss: 0.4649 - val_accuracy: 0.8089\n",
      "Epoch 1174/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.8088 - val_loss: 0.4676 - val_accuracy: 0.8089\n",
      "Epoch 1175/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.8088 - val_loss: 0.4660 - val_accuracy: 0.8044\n",
      "Epoch 1176/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4377 - accuracy: 0.8107 - val_loss: 0.4682 - val_accuracy: 0.8000\n",
      "Epoch 1177/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.8050 - val_loss: 0.4672 - val_accuracy: 0.8044\n",
      "Epoch 1178/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.8031 - val_loss: 0.4676 - val_accuracy: 0.8044\n",
      "Epoch 1179/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.8107 - val_loss: 0.4677 - val_accuracy: 0.8044\n",
      "Epoch 1180/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4445 - accuracy: 0.8011 - val_loss: 0.4694 - val_accuracy: 0.8044\n",
      "Epoch 1181/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.7935 - val_loss: 0.4687 - val_accuracy: 0.8044\n",
      "Epoch 1182/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.8088 - val_loss: 0.4680 - val_accuracy: 0.8044\n",
      "Epoch 1183/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.8088 - val_loss: 0.4716 - val_accuracy: 0.7956\n",
      "Epoch 1184/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.8050 - val_loss: 0.4679 - val_accuracy: 0.8044\n",
      "Epoch 1185/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.8145 - val_loss: 0.4669 - val_accuracy: 0.8089\n",
      "Epoch 1186/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.8107 - val_loss: 0.4675 - val_accuracy: 0.8044\n",
      "Epoch 1187/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.8069 - val_loss: 0.4677 - val_accuracy: 0.8044\n",
      "Epoch 1188/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7992 - val_loss: 0.4675 - val_accuracy: 0.8044\n",
      "Epoch 1189/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.8050 - val_loss: 0.4702 - val_accuracy: 0.8089\n",
      "Epoch 1190/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.8011 - val_loss: 0.4715 - val_accuracy: 0.8000\n",
      "Epoch 1191/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7954 - val_loss: 0.4717 - val_accuracy: 0.8089\n",
      "Epoch 1192/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.8107 - val_loss: 0.4694 - val_accuracy: 0.8089\n",
      "Epoch 1193/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.8011 - val_loss: 0.4682 - val_accuracy: 0.8044\n",
      "Epoch 1194/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.8069 - val_loss: 0.4667 - val_accuracy: 0.8089\n",
      "Epoch 1195/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.8011 - val_loss: 0.4686 - val_accuracy: 0.8044\n",
      "Epoch 1196/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.8069 - val_loss: 0.4695 - val_accuracy: 0.8089\n",
      "Epoch 1197/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7992 - val_loss: 0.4696 - val_accuracy: 0.8044\n",
      "Epoch 1198/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.8069 - val_loss: 0.4689 - val_accuracy: 0.8044\n",
      "Epoch 1199/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7935 - val_loss: 0.4693 - val_accuracy: 0.8089\n",
      "Epoch 1200/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.8184 - val_loss: 0.4666 - val_accuracy: 0.8044\n",
      "Epoch 1201/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.8011 - val_loss: 0.4691 - val_accuracy: 0.8000\n",
      "Epoch 1202/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7973 - val_loss: 0.4709 - val_accuracy: 0.7956\n",
      "Epoch 1203/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.8069 - val_loss: 0.4655 - val_accuracy: 0.8089\n",
      "Epoch 1204/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7992 - val_loss: 0.4669 - val_accuracy: 0.8044\n",
      "Epoch 1205/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.8050 - val_loss: 0.4664 - val_accuracy: 0.8089\n",
      "Epoch 1206/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.8011 - val_loss: 0.4661 - val_accuracy: 0.8044\n",
      "Epoch 1207/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.8050 - val_loss: 0.4681 - val_accuracy: 0.8044\n",
      "Epoch 1208/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.8031 - val_loss: 0.4660 - val_accuracy: 0.8089\n",
      "Epoch 1209/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7992 - val_loss: 0.4689 - val_accuracy: 0.8044\n",
      "Epoch 1210/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.8011 - val_loss: 0.4667 - val_accuracy: 0.8044\n",
      "Epoch 1211/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.8088 - val_loss: 0.4683 - val_accuracy: 0.8000\n",
      "Epoch 1212/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.8069 - val_loss: 0.4698 - val_accuracy: 0.8044\n",
      "Epoch 1213/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.8031 - val_loss: 0.4668 - val_accuracy: 0.8044\n",
      "Epoch 1214/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.8069 - val_loss: 0.4682 - val_accuracy: 0.8044\n",
      "Epoch 1215/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7992 - val_loss: 0.4671 - val_accuracy: 0.8044\n",
      "Epoch 1216/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.8126 - val_loss: 0.4669 - val_accuracy: 0.8089\n",
      "Epoch 1217/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.8107 - val_loss: 0.4687 - val_accuracy: 0.8044\n",
      "Epoch 1218/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4419 - accuracy: 0.8107 - val_loss: 0.4704 - val_accuracy: 0.8000\n",
      "Epoch 1219/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7954 - val_loss: 0.4669 - val_accuracy: 0.8044\n",
      "Epoch 1220/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.8107 - val_loss: 0.4698 - val_accuracy: 0.7956\n",
      "Epoch 1221/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.8069 - val_loss: 0.4684 - val_accuracy: 0.8044\n",
      "Epoch 1222/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7973 - val_loss: 0.4697 - val_accuracy: 0.8044\n",
      "Epoch 1223/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.8107 - val_loss: 0.4689 - val_accuracy: 0.8044\n",
      "Epoch 1224/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8069 - val_loss: 0.4677 - val_accuracy: 0.8044\n",
      "Epoch 1225/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.8031 - val_loss: 0.4691 - val_accuracy: 0.8089\n",
      "Epoch 1226/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.8107 - val_loss: 0.4699 - val_accuracy: 0.8089\n",
      "Epoch 1227/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7954 - val_loss: 0.4713 - val_accuracy: 0.8044\n",
      "Epoch 1228/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.8050 - val_loss: 0.4705 - val_accuracy: 0.8044\n",
      "Epoch 1229/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.8069 - val_loss: 0.4725 - val_accuracy: 0.8044\n",
      "Epoch 1230/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.8011 - val_loss: 0.4690 - val_accuracy: 0.8044\n",
      "Epoch 1231/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.8011 - val_loss: 0.4681 - val_accuracy: 0.8044\n",
      "Epoch 1232/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.8126 - val_loss: 0.4666 - val_accuracy: 0.8044\n",
      "Epoch 1233/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.8011 - val_loss: 0.4677 - val_accuracy: 0.8044\n",
      "Epoch 1234/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.7992 - val_loss: 0.4707 - val_accuracy: 0.8044\n",
      "Epoch 1235/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.8069 - val_loss: 0.4700 - val_accuracy: 0.8044\n",
      "Epoch 1236/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.8011 - val_loss: 0.4676 - val_accuracy: 0.8089\n",
      "Epoch 1237/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4431 - accuracy: 0.8031 - val_loss: 0.4669 - val_accuracy: 0.8044\n",
      "Epoch 1238/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7973 - val_loss: 0.4715 - val_accuracy: 0.8000\n",
      "Epoch 1239/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.7992 - val_loss: 0.4683 - val_accuracy: 0.8044\n",
      "Epoch 1240/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4425 - accuracy: 0.7992 - val_loss: 0.4710 - val_accuracy: 0.8044\n",
      "Epoch 1241/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4401 - accuracy: 0.8088 - val_loss: 0.4689 - val_accuracy: 0.8044\n",
      "Epoch 1242/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4342 - accuracy: 0.8126 - val_loss: 0.4690 - val_accuracy: 0.8044\n",
      "Epoch 1243/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4399 - accuracy: 0.8011 - val_loss: 0.4669 - val_accuracy: 0.8044\n",
      "Epoch 1244/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.8050 - val_loss: 0.4687 - val_accuracy: 0.8044\n",
      "Epoch 1245/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.8011 - val_loss: 0.4679 - val_accuracy: 0.8044\n",
      "Epoch 1246/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.8107 - val_loss: 0.4710 - val_accuracy: 0.7911\n",
      "Epoch 1247/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.8222 - val_loss: 0.4685 - val_accuracy: 0.8044\n",
      "Epoch 1248/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.8107 - val_loss: 0.4704 - val_accuracy: 0.8044\n",
      "Epoch 1249/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7992 - val_loss: 0.4700 - val_accuracy: 0.8044\n",
      "Epoch 1250/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4380 - accuracy: 0.8069 - val_loss: 0.4705 - val_accuracy: 0.8044\n",
      "Epoch 1251/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.8050 - val_loss: 0.4708 - val_accuracy: 0.8000\n",
      "Epoch 1252/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4400 - accuracy: 0.7916 - val_loss: 0.4683 - val_accuracy: 0.8044\n",
      "Epoch 1253/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.8184 - val_loss: 0.4681 - val_accuracy: 0.8089\n",
      "Epoch 1254/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7954 - val_loss: 0.4700 - val_accuracy: 0.8000\n",
      "Epoch 1255/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.8088 - val_loss: 0.4689 - val_accuracy: 0.8000\n",
      "Epoch 1256/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.8011 - val_loss: 0.4670 - val_accuracy: 0.8044\n",
      "Epoch 1257/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.8126 - val_loss: 0.4703 - val_accuracy: 0.8044\n",
      "Epoch 1258/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.8011 - val_loss: 0.4684 - val_accuracy: 0.8044\n",
      "Epoch 1259/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7992 - val_loss: 0.4711 - val_accuracy: 0.8044\n",
      "Epoch 1260/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.8088 - val_loss: 0.4696 - val_accuracy: 0.8044\n",
      "Epoch 1261/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7992 - val_loss: 0.4710 - val_accuracy: 0.8000\n",
      "Epoch 1262/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.8050 - val_loss: 0.4714 - val_accuracy: 0.8044\n",
      "Epoch 1263/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.8088 - val_loss: 0.4720 - val_accuracy: 0.8044\n",
      "Epoch 1264/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.8050 - val_loss: 0.4692 - val_accuracy: 0.8044\n",
      "Epoch 1265/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.8011 - val_loss: 0.4705 - val_accuracy: 0.8044\n",
      "Epoch 1266/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7954 - val_loss: 0.4714 - val_accuracy: 0.8044\n",
      "Epoch 1267/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4444 - accuracy: 0.7897 - val_loss: 0.4722 - val_accuracy: 0.8044\n",
      "Epoch 1268/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4431 - accuracy: 0.7992 - val_loss: 0.4716 - val_accuracy: 0.8044\n",
      "Epoch 1269/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4452 - accuracy: 0.7954 - val_loss: 0.4688 - val_accuracy: 0.8044\n",
      "Epoch 1270/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.8069 - val_loss: 0.4723 - val_accuracy: 0.8089\n",
      "Epoch 1271/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4335 - accuracy: 0.8031 - val_loss: 0.4692 - val_accuracy: 0.8044\n",
      "Epoch 1272/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7992 - val_loss: 0.4717 - val_accuracy: 0.8044\n",
      "Epoch 1273/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.8088 - val_loss: 0.4715 - val_accuracy: 0.8044\n",
      "Epoch 1274/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7992 - val_loss: 0.4714 - val_accuracy: 0.8089\n",
      "Epoch 1275/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.8069 - val_loss: 0.4711 - val_accuracy: 0.8044\n",
      "Epoch 1276/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7992 - val_loss: 0.4708 - val_accuracy: 0.8044\n",
      "Epoch 1277/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.7992 - val_loss: 0.4718 - val_accuracy: 0.8044\n",
      "Epoch 1278/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7973 - val_loss: 0.4693 - val_accuracy: 0.8044\n",
      "Epoch 1279/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.8050 - val_loss: 0.4729 - val_accuracy: 0.8044\n",
      "Epoch 1280/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4388 - accuracy: 0.7992 - val_loss: 0.4719 - val_accuracy: 0.8044\n",
      "Epoch 1281/1600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4392 - accuracy: 0.7973 - val_loss: 0.4686 - val_accuracy: 0.8044\n",
      "Epoch 1282/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4359 - accuracy: 0.8107 - val_loss: 0.4682 - val_accuracy: 0.8133\n",
      "Epoch 1283/1600\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.4481 - accuracy: 0.8050 - val_loss: 0.4746 - val_accuracy: 0.7956\n",
      "Epoch 1284/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4327 - accuracy: 0.8050 - val_loss: 0.4702 - val_accuracy: 0.8000\n",
      "Epoch 1285/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4393 - accuracy: 0.7973 - val_loss: 0.4694 - val_accuracy: 0.8044\n",
      "Epoch 1286/1600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4367 - accuracy: 0.7973 - val_loss: 0.4737 - val_accuracy: 0.8089\n",
      "Epoch 1287/1600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4340 - accuracy: 0.8107 - val_loss: 0.4702 - val_accuracy: 0.8044\n",
      "Epoch 1288/1600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4436 - accuracy: 0.7992 - val_loss: 0.4716 - val_accuracy: 0.8044\n",
      "Epoch 1289/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4366 - accuracy: 0.8069 - val_loss: 0.4699 - val_accuracy: 0.8089\n",
      "Epoch 1290/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4424 - accuracy: 0.7992 - val_loss: 0.4738 - val_accuracy: 0.8044\n",
      "Epoch 1291/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.8069 - val_loss: 0.4725 - val_accuracy: 0.8000\n",
      "Epoch 1292/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4363 - accuracy: 0.8031 - val_loss: 0.4737 - val_accuracy: 0.8000\n",
      "Epoch 1293/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.8031 - val_loss: 0.4722 - val_accuracy: 0.8044\n",
      "Epoch 1294/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.8069 - val_loss: 0.4713 - val_accuracy: 0.8044\n",
      "Epoch 1295/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4360 - accuracy: 0.8011 - val_loss: 0.4716 - val_accuracy: 0.8044\n",
      "Epoch 1296/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4442 - accuracy: 0.7992 - val_loss: 0.4732 - val_accuracy: 0.8044\n",
      "Epoch 1297/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4305 - accuracy: 0.8050 - val_loss: 0.4723 - val_accuracy: 0.8089\n",
      "Epoch 1298/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4362 - accuracy: 0.8011 - val_loss: 0.4709 - val_accuracy: 0.8044\n",
      "Epoch 1299/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4349 - accuracy: 0.8050 - val_loss: 0.4726 - val_accuracy: 0.8044\n",
      "Epoch 1300/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4426 - accuracy: 0.8050 - val_loss: 0.4750 - val_accuracy: 0.8089\n",
      "Epoch 1301/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4387 - accuracy: 0.8088 - val_loss: 0.4743 - val_accuracy: 0.8089\n",
      "Epoch 1302/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4380 - accuracy: 0.7973 - val_loss: 0.4710 - val_accuracy: 0.8089\n",
      "Epoch 1303/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4410 - accuracy: 0.7992 - val_loss: 0.4696 - val_accuracy: 0.8044\n",
      "Epoch 1304/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4420 - accuracy: 0.7935 - val_loss: 0.4712 - val_accuracy: 0.8000\n",
      "Epoch 1305/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4411 - accuracy: 0.7954 - val_loss: 0.4738 - val_accuracy: 0.8044\n",
      "Epoch 1306/1600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4357 - accuracy: 0.8069 - val_loss: 0.4761 - val_accuracy: 0.8000\n",
      "Epoch 1307/1600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.4395 - accuracy: 0.8050 - val_loss: 0.4742 - val_accuracy: 0.8000\n",
      "Epoch 1308/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4441 - accuracy: 0.8069 - val_loss: 0.4732 - val_accuracy: 0.8044\n",
      "Epoch 1309/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4384 - accuracy: 0.8050 - val_loss: 0.4737 - val_accuracy: 0.8000\n",
      "Epoch 1310/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4295 - accuracy: 0.8088 - val_loss: 0.4725 - val_accuracy: 0.8089\n",
      "Epoch 1311/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4371 - accuracy: 0.7992 - val_loss: 0.4735 - val_accuracy: 0.8044\n",
      "Epoch 1312/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4337 - accuracy: 0.8031 - val_loss: 0.4766 - val_accuracy: 0.8089\n",
      "Epoch 1313/1600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.4353 - accuracy: 0.8107 - val_loss: 0.4750 - val_accuracy: 0.8044\n",
      "Epoch 1314/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4358 - accuracy: 0.8069 - val_loss: 0.4753 - val_accuracy: 0.8044\n",
      "Epoch 1315/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.8011 - val_loss: 0.4748 - val_accuracy: 0.8044\n",
      "Epoch 1316/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.8126 - val_loss: 0.4767 - val_accuracy: 0.8000\n",
      "Epoch 1317/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7992 - val_loss: 0.4751 - val_accuracy: 0.8044\n",
      "Epoch 1318/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.8011 - val_loss: 0.4761 - val_accuracy: 0.8044\n",
      "Epoch 1319/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4399 - accuracy: 0.8011 - val_loss: 0.4742 - val_accuracy: 0.8044\n",
      "Epoch 1320/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4331 - accuracy: 0.8011 - val_loss: 0.4770 - val_accuracy: 0.8000\n",
      "Epoch 1321/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4363 - accuracy: 0.8069 - val_loss: 0.4759 - val_accuracy: 0.8044\n",
      "Epoch 1322/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4323 - accuracy: 0.8050 - val_loss: 0.4787 - val_accuracy: 0.8000\n",
      "Epoch 1323/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4366 - accuracy: 0.8050 - val_loss: 0.4765 - val_accuracy: 0.8044\n",
      "Epoch 1324/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.8126 - val_loss: 0.4780 - val_accuracy: 0.8089\n",
      "Epoch 1325/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4312 - accuracy: 0.8031 - val_loss: 0.4767 - val_accuracy: 0.8044\n",
      "Epoch 1326/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4417 - accuracy: 0.7992 - val_loss: 0.4758 - val_accuracy: 0.8044\n",
      "Epoch 1327/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4393 - accuracy: 0.8107 - val_loss: 0.4773 - val_accuracy: 0.8044\n",
      "Epoch 1328/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.8069 - val_loss: 0.4781 - val_accuracy: 0.8044\n",
      "Epoch 1329/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.8126 - val_loss: 0.4784 - val_accuracy: 0.7956\n",
      "Epoch 1330/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.7973 - val_loss: 0.4801 - val_accuracy: 0.7867\n",
      "Epoch 1331/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4374 - accuracy: 0.8011 - val_loss: 0.4764 - val_accuracy: 0.8044\n",
      "Epoch 1332/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4437 - accuracy: 0.7935 - val_loss: 0.4781 - val_accuracy: 0.7822\n",
      "Epoch 1333/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4448 - accuracy: 0.7973 - val_loss: 0.4786 - val_accuracy: 0.8044\n",
      "Epoch 1334/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.8031 - val_loss: 0.4778 - val_accuracy: 0.8044\n",
      "Epoch 1335/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4407 - accuracy: 0.8050 - val_loss: 0.4790 - val_accuracy: 0.7911\n",
      "Epoch 1336/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4370 - accuracy: 0.8050 - val_loss: 0.4789 - val_accuracy: 0.7778\n",
      "Epoch 1337/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.7992 - val_loss: 0.4813 - val_accuracy: 0.7689\n",
      "Epoch 1338/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.8031 - val_loss: 0.4753 - val_accuracy: 0.8044\n",
      "Epoch 1339/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8069 - val_loss: 0.4773 - val_accuracy: 0.7956\n",
      "Epoch 1340/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4379 - accuracy: 0.8107 - val_loss: 0.4804 - val_accuracy: 0.8044\n",
      "Epoch 1341/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.8069 - val_loss: 0.4770 - val_accuracy: 0.8044\n",
      "Epoch 1342/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.8088 - val_loss: 0.4784 - val_accuracy: 0.8000\n",
      "Epoch 1343/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.7992 - val_loss: 0.4808 - val_accuracy: 0.8044\n",
      "Epoch 1344/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.8050 - val_loss: 0.4801 - val_accuracy: 0.8044\n",
      "Epoch 1345/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4473 - accuracy: 0.8031 - val_loss: 0.4760 - val_accuracy: 0.8089\n",
      "Epoch 1346/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4331 - accuracy: 0.7992 - val_loss: 0.4771 - val_accuracy: 0.8044\n",
      "Epoch 1347/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4432 - accuracy: 0.7992 - val_loss: 0.4768 - val_accuracy: 0.8089\n",
      "Epoch 1348/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4425 - accuracy: 0.8011 - val_loss: 0.4803 - val_accuracy: 0.8044\n",
      "Epoch 1349/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4353 - accuracy: 0.8050 - val_loss: 0.4763 - val_accuracy: 0.8000\n",
      "Epoch 1350/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4367 - accuracy: 0.8069 - val_loss: 0.4754 - val_accuracy: 0.8000\n",
      "Epoch 1351/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8069 - val_loss: 0.4761 - val_accuracy: 0.8044\n",
      "Epoch 1352/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4340 - accuracy: 0.8107 - val_loss: 0.4798 - val_accuracy: 0.8000\n",
      "Epoch 1353/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4297 - accuracy: 0.8050 - val_loss: 0.4799 - val_accuracy: 0.8044\n",
      "Epoch 1354/1600\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.4332 - accuracy: 0.8050 - val_loss: 0.4785 - val_accuracy: 0.8000\n",
      "Epoch 1355/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4369 - accuracy: 0.8011 - val_loss: 0.4792 - val_accuracy: 0.8000\n",
      "Epoch 1356/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4313 - accuracy: 0.8088 - val_loss: 0.4793 - val_accuracy: 0.8000\n",
      "Epoch 1357/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4348 - accuracy: 0.8031 - val_loss: 0.4789 - val_accuracy: 0.8044\n",
      "Epoch 1358/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4370 - accuracy: 0.8126 - val_loss: 0.4802 - val_accuracy: 0.8089\n",
      "Epoch 1359/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4262 - accuracy: 0.8069 - val_loss: 0.4802 - val_accuracy: 0.8044\n",
      "Epoch 1360/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.8107 - val_loss: 0.4793 - val_accuracy: 0.8000\n",
      "Epoch 1361/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4373 - accuracy: 0.7992 - val_loss: 0.4778 - val_accuracy: 0.8000\n",
      "Epoch 1362/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.8050 - val_loss: 0.4799 - val_accuracy: 0.8000\n",
      "Epoch 1363/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.8184 - val_loss: 0.4820 - val_accuracy: 0.8000\n",
      "Epoch 1364/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.7973 - val_loss: 0.4841 - val_accuracy: 0.7956\n",
      "Epoch 1365/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.8088 - val_loss: 0.4836 - val_accuracy: 0.7911\n",
      "Epoch 1366/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.8050 - val_loss: 0.4807 - val_accuracy: 0.8044\n",
      "Epoch 1367/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.8107 - val_loss: 0.4816 - val_accuracy: 0.8044\n",
      "Epoch 1368/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7992 - val_loss: 0.4821 - val_accuracy: 0.7867\n",
      "Epoch 1369/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.8088 - val_loss: 0.4788 - val_accuracy: 0.8044\n",
      "Epoch 1370/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7973 - val_loss: 0.4811 - val_accuracy: 0.7956\n",
      "Epoch 1371/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.8031 - val_loss: 0.4805 - val_accuracy: 0.8044\n",
      "Epoch 1372/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.8107 - val_loss: 0.4774 - val_accuracy: 0.8044\n",
      "Epoch 1373/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.8050 - val_loss: 0.4785 - val_accuracy: 0.8044\n",
      "Epoch 1374/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.8107 - val_loss: 0.4804 - val_accuracy: 0.8044\n",
      "Epoch 1375/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.8088 - val_loss: 0.4811 - val_accuracy: 0.8044\n",
      "Epoch 1376/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.8050 - val_loss: 0.4793 - val_accuracy: 0.8044\n",
      "Epoch 1377/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.8031 - val_loss: 0.4785 - val_accuracy: 0.8044\n",
      "Epoch 1378/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.8011 - val_loss: 0.4776 - val_accuracy: 0.8000\n",
      "Epoch 1379/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.8069 - val_loss: 0.4811 - val_accuracy: 0.8044\n",
      "Epoch 1380/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.8069 - val_loss: 0.4796 - val_accuracy: 0.7911\n",
      "Epoch 1381/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4390 - accuracy: 0.7973 - val_loss: 0.4766 - val_accuracy: 0.8044\n",
      "Epoch 1382/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.8069 - val_loss: 0.4795 - val_accuracy: 0.8000\n",
      "Epoch 1383/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4361 - accuracy: 0.8126 - val_loss: 0.4808 - val_accuracy: 0.8000\n",
      "Epoch 1384/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.8011 - val_loss: 0.4830 - val_accuracy: 0.7911\n",
      "Epoch 1385/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.8069 - val_loss: 0.4830 - val_accuracy: 0.7822\n",
      "Epoch 1386/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7992 - val_loss: 0.4817 - val_accuracy: 0.7822\n",
      "Epoch 1387/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8126 - val_loss: 0.4814 - val_accuracy: 0.8044\n",
      "Epoch 1388/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.8069 - val_loss: 0.4810 - val_accuracy: 0.8044\n",
      "Epoch 1389/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.8031 - val_loss: 0.4805 - val_accuracy: 0.8044\n",
      "Epoch 1390/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7973 - val_loss: 0.4810 - val_accuracy: 0.8044\n",
      "Epoch 1391/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.8069 - val_loss: 0.4808 - val_accuracy: 0.8000\n",
      "Epoch 1392/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.8050 - val_loss: 0.4831 - val_accuracy: 0.8044\n",
      "Epoch 1393/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.8031 - val_loss: 0.4817 - val_accuracy: 0.8044\n",
      "Epoch 1394/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.8011 - val_loss: 0.4806 - val_accuracy: 0.8000\n",
      "Epoch 1395/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.8069 - val_loss: 0.4809 - val_accuracy: 0.8000\n",
      "Epoch 1396/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.8088 - val_loss: 0.4851 - val_accuracy: 0.8044\n",
      "Epoch 1397/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.8050 - val_loss: 0.4836 - val_accuracy: 0.8044\n",
      "Epoch 1398/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.8069 - val_loss: 0.4861 - val_accuracy: 0.8044\n",
      "Epoch 1399/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4302 - accuracy: 0.8088 - val_loss: 0.4813 - val_accuracy: 0.8000\n",
      "Epoch 1400/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4363 - accuracy: 0.8011 - val_loss: 0.4842 - val_accuracy: 0.8044\n",
      "Epoch 1401/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.8088 - val_loss: 0.4821 - val_accuracy: 0.8089\n",
      "Epoch 1402/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4392 - accuracy: 0.8050 - val_loss: 0.4849 - val_accuracy: 0.8044\n",
      "Epoch 1403/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.8069 - val_loss: 0.4835 - val_accuracy: 0.7822\n",
      "Epoch 1404/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.8050 - val_loss: 0.4844 - val_accuracy: 0.7956\n",
      "Epoch 1405/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4318 - accuracy: 0.8164 - val_loss: 0.4860 - val_accuracy: 0.7867\n",
      "Epoch 1406/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4357 - accuracy: 0.8050 - val_loss: 0.4828 - val_accuracy: 0.8044\n",
      "Epoch 1407/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.8050 - val_loss: 0.4826 - val_accuracy: 0.8044\n",
      "Epoch 1408/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.8050 - val_loss: 0.4803 - val_accuracy: 0.8044\n",
      "Epoch 1409/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7935 - val_loss: 0.4824 - val_accuracy: 0.7911\n",
      "Epoch 1410/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.8069 - val_loss: 0.4823 - val_accuracy: 0.7956\n",
      "Epoch 1411/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.8050 - val_loss: 0.4876 - val_accuracy: 0.7600\n",
      "Epoch 1412/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.8031 - val_loss: 0.4851 - val_accuracy: 0.7867\n",
      "Epoch 1413/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.8088 - val_loss: 0.4840 - val_accuracy: 0.7911\n",
      "Epoch 1414/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.8011 - val_loss: 0.4843 - val_accuracy: 0.7867\n",
      "Epoch 1415/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.8107 - val_loss: 0.4841 - val_accuracy: 0.7911\n",
      "Epoch 1416/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8031 - val_loss: 0.4839 - val_accuracy: 0.7778\n",
      "Epoch 1417/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.8164 - val_loss: 0.4833 - val_accuracy: 0.8044\n",
      "Epoch 1418/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.8107 - val_loss: 0.4839 - val_accuracy: 0.8044\n",
      "Epoch 1419/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.8069 - val_loss: 0.4833 - val_accuracy: 0.8044\n",
      "Epoch 1420/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.8145 - val_loss: 0.4803 - val_accuracy: 0.8000\n",
      "Epoch 1421/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.8031 - val_loss: 0.4839 - val_accuracy: 0.8000\n",
      "Epoch 1422/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.8088 - val_loss: 0.4841 - val_accuracy: 0.8000\n",
      "Epoch 1423/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4332 - accuracy: 0.8031 - val_loss: 0.4813 - val_accuracy: 0.7956\n",
      "Epoch 1424/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4426 - accuracy: 0.8069 - val_loss: 0.4831 - val_accuracy: 0.7956\n",
      "Epoch 1425/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.8050 - val_loss: 0.4797 - val_accuracy: 0.8000\n",
      "Epoch 1426/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.8164 - val_loss: 0.4813 - val_accuracy: 0.8044\n",
      "Epoch 1427/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.8069 - val_loss: 0.4834 - val_accuracy: 0.8000\n",
      "Epoch 1428/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.8107 - val_loss: 0.4872 - val_accuracy: 0.8000\n",
      "Epoch 1429/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.8126 - val_loss: 0.4840 - val_accuracy: 0.8000\n",
      "Epoch 1430/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4307 - accuracy: 0.8069 - val_loss: 0.4798 - val_accuracy: 0.8044\n",
      "Epoch 1431/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4360 - accuracy: 0.8107 - val_loss: 0.4784 - val_accuracy: 0.7956\n",
      "Epoch 1432/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4352 - accuracy: 0.8011 - val_loss: 0.4814 - val_accuracy: 0.8000\n",
      "Epoch 1433/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4307 - accuracy: 0.8107 - val_loss: 0.4852 - val_accuracy: 0.7956\n",
      "Epoch 1434/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.8050 - val_loss: 0.4871 - val_accuracy: 0.7911\n",
      "Epoch 1435/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7973 - val_loss: 0.4855 - val_accuracy: 0.7778\n",
      "Epoch 1436/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4325 - accuracy: 0.8107 - val_loss: 0.4883 - val_accuracy: 0.7867\n",
      "Epoch 1437/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.8031 - val_loss: 0.4845 - val_accuracy: 0.7644\n",
      "Epoch 1438/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4292 - accuracy: 0.8031 - val_loss: 0.4874 - val_accuracy: 0.7822\n",
      "Epoch 1439/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4351 - accuracy: 0.8069 - val_loss: 0.4882 - val_accuracy: 0.7911\n",
      "Epoch 1440/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4248 - accuracy: 0.8164 - val_loss: 0.4866 - val_accuracy: 0.7733\n",
      "Epoch 1441/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8164 - val_loss: 0.4885 - val_accuracy: 0.8044\n",
      "Epoch 1442/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4312 - accuracy: 0.7992 - val_loss: 0.4913 - val_accuracy: 0.7867\n",
      "Epoch 1443/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.8050 - val_loss: 0.4849 - val_accuracy: 0.7733\n",
      "Epoch 1444/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.8031 - val_loss: 0.4847 - val_accuracy: 0.7867\n",
      "Epoch 1445/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.8107 - val_loss: 0.4847 - val_accuracy: 0.8000\n",
      "Epoch 1446/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4339 - accuracy: 0.7992 - val_loss: 0.4858 - val_accuracy: 0.7733\n",
      "Epoch 1447/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4350 - accuracy: 0.8164 - val_loss: 0.4851 - val_accuracy: 0.7956\n",
      "Epoch 1448/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.8031 - val_loss: 0.4860 - val_accuracy: 0.7956\n",
      "Epoch 1449/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.8088 - val_loss: 0.4856 - val_accuracy: 0.8000\n",
      "Epoch 1450/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.8011 - val_loss: 0.4800 - val_accuracy: 0.8044\n",
      "Epoch 1451/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4347 - accuracy: 0.8069 - val_loss: 0.4827 - val_accuracy: 0.8044\n",
      "Epoch 1452/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.8088 - val_loss: 0.4850 - val_accuracy: 0.7956\n",
      "Epoch 1453/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7916 - val_loss: 0.4853 - val_accuracy: 0.7911\n",
      "Epoch 1454/1600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4308 - accuracy: 0.8107 - val_loss: 0.4895 - val_accuracy: 0.7956\n",
      "Epoch 1455/1600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4300 - accuracy: 0.8107 - val_loss: 0.4861 - val_accuracy: 0.7600\n",
      "Epoch 1456/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4322 - accuracy: 0.8088 - val_loss: 0.4863 - val_accuracy: 0.7778\n",
      "Epoch 1457/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4352 - accuracy: 0.8011 - val_loss: 0.4862 - val_accuracy: 0.8000\n",
      "Epoch 1458/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4429 - accuracy: 0.8011 - val_loss: 0.4820 - val_accuracy: 0.7689\n",
      "Epoch 1459/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4423 - accuracy: 0.8031 - val_loss: 0.4828 - val_accuracy: 0.7644\n",
      "Epoch 1460/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4357 - accuracy: 0.7973 - val_loss: 0.4832 - val_accuracy: 0.7644\n",
      "Epoch 1461/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4354 - accuracy: 0.8088 - val_loss: 0.4849 - val_accuracy: 0.7867\n",
      "Epoch 1462/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4330 - accuracy: 0.8050 - val_loss: 0.4873 - val_accuracy: 0.7867\n",
      "Epoch 1463/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4283 - accuracy: 0.8069 - val_loss: 0.4866 - val_accuracy: 0.7867\n",
      "Epoch 1464/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4341 - accuracy: 0.8011 - val_loss: 0.4915 - val_accuracy: 0.7600\n",
      "Epoch 1465/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4333 - accuracy: 0.8050 - val_loss: 0.4873 - val_accuracy: 0.7956\n",
      "Epoch 1466/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4384 - accuracy: 0.8031 - val_loss: 0.4829 - val_accuracy: 0.7956\n",
      "Epoch 1467/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4356 - accuracy: 0.8069 - val_loss: 0.4891 - val_accuracy: 0.7956\n",
      "Epoch 1468/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.8107 - val_loss: 0.4875 - val_accuracy: 0.7911\n",
      "Epoch 1469/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4328 - accuracy: 0.8050 - val_loss: 0.4891 - val_accuracy: 0.8044\n",
      "Epoch 1470/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4315 - accuracy: 0.8107 - val_loss: 0.4894 - val_accuracy: 0.7911\n",
      "Epoch 1471/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4311 - accuracy: 0.8011 - val_loss: 0.4898 - val_accuracy: 0.7867\n",
      "Epoch 1472/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.8126 - val_loss: 0.4897 - val_accuracy: 0.8000\n",
      "Epoch 1473/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4345 - accuracy: 0.8088 - val_loss: 0.4878 - val_accuracy: 0.8000\n",
      "Epoch 1474/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.8145 - val_loss: 0.4899 - val_accuracy: 0.8000\n",
      "Epoch 1475/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4266 - accuracy: 0.7992 - val_loss: 0.4861 - val_accuracy: 0.7956\n",
      "Epoch 1476/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4300 - accuracy: 0.8107 - val_loss: 0.4883 - val_accuracy: 0.8044\n",
      "Epoch 1477/1600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4320 - accuracy: 0.8088 - val_loss: 0.4913 - val_accuracy: 0.8000\n",
      "Epoch 1478/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4243 - accuracy: 0.8126 - val_loss: 0.4890 - val_accuracy: 0.7956\n",
      "Epoch 1479/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4345 - accuracy: 0.8050 - val_loss: 0.4890 - val_accuracy: 0.8000\n",
      "Epoch 1480/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4318 - accuracy: 0.8050 - val_loss: 0.4856 - val_accuracy: 0.8044\n",
      "Epoch 1481/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4357 - accuracy: 0.8069 - val_loss: 0.4886 - val_accuracy: 0.8044\n",
      "Epoch 1482/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4251 - accuracy: 0.8107 - val_loss: 0.4917 - val_accuracy: 0.8000\n",
      "Epoch 1483/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4328 - accuracy: 0.8069 - val_loss: 0.4911 - val_accuracy: 0.7867\n",
      "Epoch 1484/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4381 - accuracy: 0.8069 - val_loss: 0.4895 - val_accuracy: 0.8000\n",
      "Epoch 1485/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4446 - accuracy: 0.7992 - val_loss: 0.4887 - val_accuracy: 0.7956\n",
      "Epoch 1486/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.8031 - val_loss: 0.4887 - val_accuracy: 0.8000\n",
      "Epoch 1487/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4375 - accuracy: 0.7992 - val_loss: 0.4866 - val_accuracy: 0.7956\n",
      "Epoch 1488/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4327 - accuracy: 0.8031 - val_loss: 0.4868 - val_accuracy: 0.8000\n",
      "Epoch 1489/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4315 - accuracy: 0.8107 - val_loss: 0.4888 - val_accuracy: 0.8044\n",
      "Epoch 1490/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4331 - accuracy: 0.8050 - val_loss: 0.4877 - val_accuracy: 0.8000\n",
      "Epoch 1491/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.8164 - val_loss: 0.4934 - val_accuracy: 0.7778\n",
      "Epoch 1492/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4373 - accuracy: 0.8126 - val_loss: 0.4885 - val_accuracy: 0.7644\n",
      "Epoch 1493/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.8011 - val_loss: 0.4877 - val_accuracy: 0.7778\n",
      "Epoch 1494/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.8164 - val_loss: 0.4890 - val_accuracy: 0.8044\n",
      "Epoch 1495/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.8050 - val_loss: 0.4854 - val_accuracy: 0.7956\n",
      "Epoch 1496/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.8050 - val_loss: 0.4858 - val_accuracy: 0.7911\n",
      "Epoch 1497/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8069 - val_loss: 0.4898 - val_accuracy: 0.7956\n",
      "Epoch 1498/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7954 - val_loss: 0.4915 - val_accuracy: 0.8000\n",
      "Epoch 1499/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.8050 - val_loss: 0.4881 - val_accuracy: 0.7956\n",
      "Epoch 1500/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4242 - accuracy: 0.8031 - val_loss: 0.4906 - val_accuracy: 0.8000\n",
      "Epoch 1501/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.8069 - val_loss: 0.4855 - val_accuracy: 0.7822\n",
      "Epoch 1502/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4416 - accuracy: 0.8050 - val_loss: 0.4848 - val_accuracy: 0.8000\n",
      "Epoch 1503/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.8107 - val_loss: 0.4913 - val_accuracy: 0.7956\n",
      "Epoch 1504/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.8126 - val_loss: 0.4917 - val_accuracy: 0.8000\n",
      "Epoch 1505/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.8107 - val_loss: 0.4897 - val_accuracy: 0.8000\n",
      "Epoch 1506/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.8088 - val_loss: 0.4933 - val_accuracy: 0.7956\n",
      "Epoch 1507/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.8069 - val_loss: 0.4823 - val_accuracy: 0.7956\n",
      "Epoch 1508/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.8069 - val_loss: 0.4827 - val_accuracy: 0.8000\n",
      "Epoch 1509/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4349 - accuracy: 0.8031 - val_loss: 0.4867 - val_accuracy: 0.7911\n",
      "Epoch 1510/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4259 - accuracy: 0.8088 - val_loss: 0.4891 - val_accuracy: 0.7956\n",
      "Epoch 1511/1600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.4324 - accuracy: 0.8050 - val_loss: 0.4904 - val_accuracy: 0.7778\n",
      "Epoch 1512/1600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4312 - accuracy: 0.8164 - val_loss: 0.4855 - val_accuracy: 0.7644\n",
      "Epoch 1513/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4315 - accuracy: 0.8203 - val_loss: 0.4895 - val_accuracy: 0.7511\n",
      "Epoch 1514/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4289 - accuracy: 0.7973 - val_loss: 0.4963 - val_accuracy: 0.7778\n",
      "Epoch 1515/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4290 - accuracy: 0.8050 - val_loss: 0.4950 - val_accuracy: 0.7600\n",
      "Epoch 1516/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4329 - accuracy: 0.8107 - val_loss: 0.4903 - val_accuracy: 0.7778\n",
      "Epoch 1517/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4339 - accuracy: 0.8050 - val_loss: 0.4889 - val_accuracy: 0.7689\n",
      "Epoch 1518/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4317 - accuracy: 0.7954 - val_loss: 0.4928 - val_accuracy: 0.7956\n",
      "Epoch 1519/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4285 - accuracy: 0.8088 - val_loss: 0.4833 - val_accuracy: 0.7822\n",
      "Epoch 1520/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4393 - accuracy: 0.7992 - val_loss: 0.4881 - val_accuracy: 0.8000\n",
      "Epoch 1521/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.8011 - val_loss: 0.4887 - val_accuracy: 0.7733\n",
      "Epoch 1522/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4310 - accuracy: 0.8031 - val_loss: 0.4940 - val_accuracy: 0.8000\n",
      "Epoch 1523/1600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4368 - accuracy: 0.8088 - val_loss: 0.4905 - val_accuracy: 0.7911\n",
      "Epoch 1524/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4357 - accuracy: 0.8011 - val_loss: 0.4883 - val_accuracy: 0.7644\n",
      "Epoch 1525/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.8069 - val_loss: 0.4931 - val_accuracy: 0.7822\n",
      "Epoch 1526/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.8126 - val_loss: 0.4935 - val_accuracy: 0.7956\n",
      "Epoch 1527/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4311 - accuracy: 0.8069 - val_loss: 0.4863 - val_accuracy: 0.7778\n",
      "Epoch 1528/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4295 - accuracy: 0.8011 - val_loss: 0.4879 - val_accuracy: 0.8044\n",
      "Epoch 1529/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.8184 - val_loss: 0.4891 - val_accuracy: 0.7956\n",
      "Epoch 1530/1600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4269 - accuracy: 0.8145 - val_loss: 0.4954 - val_accuracy: 0.7867\n",
      "Epoch 1531/1600\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.4285 - accuracy: 0.8011 - val_loss: 0.4840 - val_accuracy: 0.7867\n",
      "Epoch 1532/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4321 - accuracy: 0.8050 - val_loss: 0.4828 - val_accuracy: 0.7778\n",
      "Epoch 1533/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4281 - accuracy: 0.7992 - val_loss: 0.4899 - val_accuracy: 0.7867\n",
      "Epoch 1534/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4377 - accuracy: 0.8031 - val_loss: 0.4879 - val_accuracy: 0.8000\n",
      "Epoch 1535/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.8031 - val_loss: 0.4888 - val_accuracy: 0.7956\n",
      "Epoch 1536/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4352 - accuracy: 0.8164 - val_loss: 0.4901 - val_accuracy: 0.7867\n",
      "Epoch 1537/1600\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.4356 - accuracy: 0.8069 - val_loss: 0.4925 - val_accuracy: 0.7911\n",
      "Epoch 1538/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.8050 - val_loss: 0.4904 - val_accuracy: 0.8000\n",
      "Epoch 1539/1600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4319 - accuracy: 0.8088 - val_loss: 0.4876 - val_accuracy: 0.8000\n",
      "Epoch 1540/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4333 - accuracy: 0.8069 - val_loss: 0.4910 - val_accuracy: 0.8000\n",
      "Epoch 1541/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4352 - accuracy: 0.8145 - val_loss: 0.4942 - val_accuracy: 0.8044\n",
      "Epoch 1542/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.8031 - val_loss: 0.4931 - val_accuracy: 0.7644\n",
      "Epoch 1543/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.8164 - val_loss: 0.4990 - val_accuracy: 0.7911\n",
      "Epoch 1544/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7954 - val_loss: 0.4954 - val_accuracy: 0.7689\n",
      "Epoch 1545/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.8050 - val_loss: 0.4947 - val_accuracy: 0.7867\n",
      "Epoch 1546/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.8031 - val_loss: 0.4884 - val_accuracy: 0.7689\n",
      "Epoch 1547/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4288 - accuracy: 0.8069 - val_loss: 0.4874 - val_accuracy: 0.7956\n",
      "Epoch 1548/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.8031 - val_loss: 0.4932 - val_accuracy: 0.8000\n",
      "Epoch 1549/1600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4351 - accuracy: 0.7992 - val_loss: 0.4874 - val_accuracy: 0.8000\n",
      "Epoch 1550/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4316 - accuracy: 0.8069 - val_loss: 0.4928 - val_accuracy: 0.8000\n",
      "Epoch 1551/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.8088 - val_loss: 0.4832 - val_accuracy: 0.7911\n",
      "Epoch 1552/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4343 - accuracy: 0.8069 - val_loss: 0.4867 - val_accuracy: 0.7911\n",
      "Epoch 1553/1600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4246 - accuracy: 0.8184 - val_loss: 0.4948 - val_accuracy: 0.7956\n",
      "Epoch 1554/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4259 - accuracy: 0.8107 - val_loss: 0.4939 - val_accuracy: 0.8000\n",
      "Epoch 1555/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4318 - accuracy: 0.7935 - val_loss: 0.4939 - val_accuracy: 0.7911\n",
      "Epoch 1556/1600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4310 - accuracy: 0.7973 - val_loss: 0.4861 - val_accuracy: 0.7556\n",
      "Epoch 1557/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4358 - accuracy: 0.8069 - val_loss: 0.4835 - val_accuracy: 0.7689\n",
      "Epoch 1558/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.8050 - val_loss: 0.4827 - val_accuracy: 0.7956\n",
      "Epoch 1559/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4290 - accuracy: 0.8088 - val_loss: 0.4831 - val_accuracy: 0.8000\n",
      "Epoch 1560/1600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4306 - accuracy: 0.8107 - val_loss: 0.4883 - val_accuracy: 0.8000\n",
      "Epoch 1561/1600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4328 - accuracy: 0.8069 - val_loss: 0.4931 - val_accuracy: 0.7911\n",
      "Epoch 1562/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.8107 - val_loss: 0.4985 - val_accuracy: 0.7956\n",
      "Epoch 1563/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7935 - val_loss: 0.4921 - val_accuracy: 0.7778\n",
      "Epoch 1564/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.8164 - val_loss: 0.4903 - val_accuracy: 0.7956\n",
      "Epoch 1565/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.8107 - val_loss: 0.4888 - val_accuracy: 0.8000\n",
      "Epoch 1566/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4298 - accuracy: 0.8050 - val_loss: 0.4952 - val_accuracy: 0.7911\n",
      "Epoch 1567/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.8107 - val_loss: 0.4862 - val_accuracy: 0.8000\n",
      "Epoch 1568/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.8069 - val_loss: 0.4953 - val_accuracy: 0.7956\n",
      "Epoch 1569/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.8011 - val_loss: 0.4971 - val_accuracy: 0.7822\n",
      "Epoch 1570/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7992 - val_loss: 0.4879 - val_accuracy: 0.7733\n",
      "Epoch 1571/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.8069 - val_loss: 0.4902 - val_accuracy: 0.7867\n",
      "Epoch 1572/1600\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.8145 - val_loss: 0.4966 - val_accuracy: 0.7956\n",
      "Epoch 1573/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.8031 - val_loss: 0.4942 - val_accuracy: 0.7956\n",
      "Epoch 1574/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.8011 - val_loss: 0.4966 - val_accuracy: 0.7911\n",
      "Epoch 1575/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.8011 - val_loss: 0.4968 - val_accuracy: 0.7778\n",
      "Epoch 1576/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.8126 - val_loss: 0.4947 - val_accuracy: 0.7778\n",
      "Epoch 1577/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.8031 - val_loss: 0.4951 - val_accuracy: 0.7689\n",
      "Epoch 1578/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4263 - accuracy: 0.8069 - val_loss: 0.4987 - val_accuracy: 0.7822\n",
      "Epoch 1579/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4289 - accuracy: 0.8031 - val_loss: 0.4883 - val_accuracy: 0.7644\n",
      "Epoch 1580/1600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4309 - accuracy: 0.8088 - val_loss: 0.4872 - val_accuracy: 0.7911\n",
      "Epoch 1581/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4329 - accuracy: 0.8050 - val_loss: 0.4970 - val_accuracy: 0.7822\n",
      "Epoch 1582/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.8126 - val_loss: 0.4961 - val_accuracy: 0.7778\n",
      "Epoch 1583/1600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4292 - accuracy: 0.8069 - val_loss: 0.4996 - val_accuracy: 0.7733\n",
      "Epoch 1584/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.8126 - val_loss: 0.4993 - val_accuracy: 0.7511\n",
      "Epoch 1585/1600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4344 - accuracy: 0.8031 - val_loss: 0.4966 - val_accuracy: 0.7956\n",
      "Epoch 1586/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.8011 - val_loss: 0.4927 - val_accuracy: 0.7911\n",
      "Epoch 1587/1600\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7973 - val_loss: 0.4936 - val_accuracy: 0.7956\n",
      "Epoch 1588/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.8126 - val_loss: 0.4973 - val_accuracy: 0.7956\n",
      "Epoch 1589/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.8031 - val_loss: 0.4937 - val_accuracy: 0.7911\n",
      "Epoch 1590/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.8107 - val_loss: 0.4935 - val_accuracy: 0.7911\n",
      "Epoch 1591/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.8126 - val_loss: 0.4972 - val_accuracy: 0.8044\n",
      "Epoch 1592/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.8126 - val_loss: 0.4943 - val_accuracy: 0.7644\n",
      "Epoch 1593/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.8126 - val_loss: 0.4952 - val_accuracy: 0.8000\n",
      "Epoch 1594/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.8088 - val_loss: 0.4969 - val_accuracy: 0.7867\n",
      "Epoch 1595/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7954 - val_loss: 0.4967 - val_accuracy: 0.7600\n",
      "Epoch 1596/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.8164 - val_loss: 0.4953 - val_accuracy: 0.8044\n",
      "Epoch 1597/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8069 - val_loss: 0.4978 - val_accuracy: 0.7956\n",
      "Epoch 1598/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.8145 - val_loss: 0.4958 - val_accuracy: 0.7956\n",
      "Epoch 1599/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8107 - val_loss: 0.4927 - val_accuracy: 0.7867\n",
      "Epoch 1600/1600\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.8126 - val_loss: 0.4972 - val_accuracy: 0.7733\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs=1600,validation_data = (X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.699272</td>\n",
       "      <td>0.483748</td>\n",
       "      <td>0.678429</td>\n",
       "      <td>0.742222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.663897</td>\n",
       "      <td>0.747610</td>\n",
       "      <td>0.643638</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.631807</td>\n",
       "      <td>0.768642</td>\n",
       "      <td>0.613260</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.600378</td>\n",
       "      <td>0.768642</td>\n",
       "      <td>0.584342</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.572861</td>\n",
       "      <td>0.768642</td>\n",
       "      <td>0.565927</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  0.699272  0.483748  0.678429      0.742222\n",
       "1  0.663897  0.747610  0.643638      0.746667\n",
       "2  0.631807  0.768642  0.613260      0.746667\n",
       "3  0.600378  0.768642  0.584342      0.746667\n",
       "4  0.572861  0.768642  0.565927      0.746667"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9030361610>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "losses['loss'].plot(label='Training Loss')\n",
    "losses['val_loss'].plot(label='Validation Loss')\n",
    "plt.legend(loc='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4972 - accuracy: 0.7733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.497222900390625, 0.7733333110809326]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(predictions.round(3),columns=['Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prediction\n",
       "0       0.095\n",
       "1       0.485\n",
       "2       0.086\n",
       "3       0.072\n",
       "4       0.087"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 225 entries, 0 to 224\n",
      "Data columns (total 1 columns):\n",
      "Prediction    225 non-null float32\n",
      "dtypes: float32(1)\n",
      "memory usage: 1.0 KB\n"
     ]
    }
   ],
   "source": [
    " predictions_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df['Row ID'] = range(0,225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Row ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.095</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.091</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.092</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0.342</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.103</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Prediction  Row ID\n",
       "220       0.095     220\n",
       "221       0.091     221\n",
       "222       0.092     222\n",
       "223       0.342     223\n",
       "224       0.103     224"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.996999979019165"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df['Prediction'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01899999938905239"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df['Prediction'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (predictions > 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.79      0.86       201\n",
      "        True       0.26      0.62      0.37        24\n",
      "\n",
      "    accuracy                           0.77       225\n",
      "   macro avg       0.60      0.71      0.62       225\n",
      "weighted avg       0.87      0.77      0.81       225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(predictions.reshape(225,), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Happy Learning!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
